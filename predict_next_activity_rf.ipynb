{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44387976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sliding_window' from 'C:\\\\Users\\\\suhwanlee\\\\Desktop\\\\project\\\\streaming_anomaly_detect\\\\sliding_window.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from river import stream,tree,metrics\n",
    "import utils\n",
    "from encoding import prefix_bin\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sliding_window\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import datetime, time\n",
    "import importlib\n",
    "importlib.reload(sliding_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f424c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './data/loan_baseline.pnml_noise_0.15_iteration_1_seed_614_sample.csv'\n",
    "\n",
    "\n",
    "dataset = stream.iter_csv(\n",
    "            file_name\n",
    "#             './data/loan_baseline.pnml_noise_0.15_iteration_1_seed_614_simple.csv',\n",
    "            )\n",
    "\n",
    "totallength = len(list(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd08beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stream.iter_csv(\n",
    "            file_name,\n",
    "            drop=['noise', 'lifecycle:transition', 'Variant', 'Variant index'],\n",
    "            )\n",
    "enctype = 'Index-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7654d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pair = {\n",
    "'Case ID':'caseid',\n",
    "'Activity':'activity',\n",
    "# 'Resource':'resource',\n",
    "'Complete Timestamp':'ts',\n",
    "}\n",
    "catatars= ['activity']#,'resource']\n",
    "\n",
    "case_dict ={}\n",
    "training_models ={}\n",
    "\n",
    "casecount = 0\n",
    "rowcounter = 0\n",
    "resultdict ={}\n",
    "acc_dict ={}\n",
    "prefix_wise_window = {}\n",
    "prediction_result = {}\n",
    "graceperiod_finish=0\n",
    "finishedcases = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f457584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window for training setting\n",
    "window_size = 100\n",
    "retraining_size = 20\n",
    "training_window = sliding_window.training_window(window_size,retraining_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bef05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_progress(row_counting, total_length, interval=500):\n",
    "    if rowcounter%interval == 0:\n",
    "        print(round(rowcounter*100/totallength,2) ,'%', 'Case finished: %s'%(casecount), 'Running cases: %s'%(len(case_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dc27209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_stage(window, training_models):\n",
    "    '''\n",
    "    Manage training stage of streaming anomaly detection\n",
    "    ----------\n",
    "    Parameters\n",
    "    window: class training_window\n",
    "        Sliding window with training data\n",
    "    training_models: dict\n",
    "        Trained detector by prefix stored in. Default is randomforest\n",
    "    ----------\n",
    "    Return\n",
    "    training_models\n",
    "    '''\n",
    "    pw_window = window.prefix_wise_window()\n",
    "    for x in pw_window:\n",
    "        clf  = RandomForestClassifier()\n",
    "        training_x = pw_window[x][0]\n",
    "        training_y = pw_window[x][1]\n",
    "        \n",
    "        clf.fit(pw_window[x][0],pw_window[x][1])\n",
    "        if 'detector_%s'%(x) not in training_models:\n",
    "            training_models['detector_%s'%(x)] =[0,0]\n",
    "        training_models['detector_%s'%(x)][0] += 1\n",
    "        training_models['detector_%s'%(x)][1] = clf\n",
    "    return training_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4594b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_activity_proba(last_event):\n",
    "    '''\n",
    "    Predict next activity prediction \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    last_event: case_bin\n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    modelid, prediction\n",
    "    \n",
    "    '''\n",
    "    feature_matrix = prefix_wise_window['window_%s'%(last_event.prefix_length)][0].columns.values\n",
    "    current_event = utils.readjustment_training(last_event.encoded, feature_matrix)\n",
    "    current_event = pd.Series(current_event).to_frame().T\n",
    "    prediction = [training_models['detector_window_%s'%(last_event.prefix_length)][1].predict_proba(current_event), training_models['detector_window_%s'%(last_event.prefix_length)][1].classes_]\n",
    "    modelid = training_models['detector_window_%s'%(last_event.prefix_length)][0]\n",
    "\n",
    "    return modelid, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ea7b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_event(case_bin):\n",
    "    '''\n",
    "    Generate start event before first event\n",
    "    '''\n",
    "    print(case_bin.event['ts'])\n",
    "    empty_data ={'activity':'Start signal', 'ts':datetime.datetime.strftime(case_bin.event['ts'], '%Y-%m-%d %H:%M:%S')}\n",
    "    start_event = prefix_bin(case_bin.caseid, empty_data)\n",
    "    start_event.set_prefix_length(0)\n",
    "    start_event.update_encoded(catattrs=catatars,enctype=enctype)\n",
    "    start_event.update_truelabel(case_bin.event['activity'])\n",
    "    return start_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebdc5a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % Case finished: 0 Running cases: 0\n",
      "5.8 % Case finished: 29 Running cases: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SUHWAN~1\\AppData\\Local\\Temp/ipykernel_4196/3204940450.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mtraining_window\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mcaseid\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcase_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcaseid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtraining_window\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretraining\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtraining_window\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretraining_count\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0mtraining_models\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_window\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_models\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[0mprefix_wise_window\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_window\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefix_wise_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SUHWAN~1\\AppData\\Local\\Temp/ipykernel_4196/4258212945.py\u001b[0m in \u001b[0;36mtraining_stage\u001b[1;34m(window, training_models)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mtraining_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpw_window\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpw_window\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpw_window\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'detector_%s'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraining_models\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mtraining_models\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'detector_%s'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    375\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m             trees = [self._make_estimator(append=False,\n\u001b[0m\u001b[0;32m    378\u001b[0m                                           random_state=random_state)\n\u001b[0;32m    379\u001b[0m                      for i in range(n_more_estimators)]\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    375\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m             trees = [self._make_estimator(append=False,\n\u001b[0m\u001b[0;32m    378\u001b[0m                                           random_state=random_state)\n\u001b[0;32m    379\u001b[0m                      for i in range(n_more_estimators)]\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[1;34m(self, append, random_state)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m    150\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         estimator.set_params(**{p: getattr(self, p)\n\u001b[0m\u001b[0;32m    152\u001b[0m                                 for p in self.estimator_params})\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;31m# Simple optimization to gain speed (inspect is slow)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mvalid_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mnested_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# grouped by prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mget_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \"\"\"\n\u001b[0;32m    193\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_params'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;31m# to represent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0minit_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[1;32mc:\\python\\lib\\inspect.py\u001b[0m in \u001b[0;36msignature\u001b[1;34m(obj, follow_wrapped)\u001b[0m\n\u001b[0;32m   3128\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3129\u001b[0m     \u001b[1;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[1;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[0;32m   2877\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfrom_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2878\u001b[0m         \u001b[1;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2879\u001b[1;33m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0m\u001b[0;32m   2880\u001b[0m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[0;32m   2881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[0;32m   2328\u001b[0m         \u001b[1;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2329\u001b[0m         \u001b[1;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2330\u001b[1;33m         return _signature_from_function(sigcls, obj,\n\u001b[0m\u001b[0;32m   2331\u001b[0m                                         skip_bound_arg=skip_bound_arg)\n\u001b[0;32m   2332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[1;34m(cls, func, skip_bound_arg)\u001b[0m\n\u001b[0;32m   2221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2222\u001b[0m         \u001b[0mannotation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2223\u001b[1;33m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[0m\u001b[0;32m   2224\u001b[0m                                     \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_KEYWORD_ONLY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2225\u001b[0m                                     default=default))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for x,y in dataset:\n",
    "    display_progress(rowcounter, totallength)\n",
    "    rowcounter +=1\n",
    "    \n",
    "    utils.dictkey_chg(x, key_pair)\n",
    "    # Event stream change dictionary keys\n",
    "    x['ts'] = x['ts'][:-4]\n",
    "    \n",
    "    # Check label possible\n",
    "    \n",
    "    # Initialize case by prefix length\n",
    "    caseid = x['caseid']\n",
    "    x.pop('caseid')\n",
    "    \n",
    "    case_bin = prefix_bin(caseid, x)\n",
    "    \n",
    "    if caseid not in list(case_dict.keys()):\n",
    "        case_dict[caseid] = []\n",
    "        case_bin.set_prefix_length(1)\n",
    "        \n",
    "    elif caseid in finishedcases:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        case_bin.set_prefix_length(len(case_dict[caseid])+1)\n",
    "        case_bin.set_prev_enc(case_dict[caseid][-1])\n",
    "    \n",
    "    # Encode event and cases and add to DB\n",
    "    ts = case_bin.event['ts']\n",
    "    case_bin.update_encoded(catattrs=catatars,enctype=enctype)\n",
    "    \n",
    "    # Set current activity as outcome of previous event\n",
    "    if case_bin.prefix_length != 1:\n",
    "        case_bin.prev_enc.update_truelabel(x['activity'])\n",
    "\n",
    "    # First prediction for current event\n",
    "    \n",
    "    last_event = case_bin\n",
    "    modelid = 'None'\n",
    "    prediction = 'Not Available'\n",
    "\n",
    "    if len(training_window.getAllitems()) !=0:\n",
    "        if 'window_%s'%(last_event.prefix_length) in list(prefix_wise_window.keys()) and 'detector_window_%s'%(last_event.prefix_length) in training_models.keys():\n",
    "            modelid, prediction = predict_activity_proba(last_event)\n",
    "#             feature_matrix = prefix_wise_window['window_%s'%(last_event.prefix_length)][0].columns.values\n",
    "#             current_event = utils.readjustment_training(last_event.encoded, feature_matrix)\n",
    "#             current_event = pd.Series(current_event).to_frame().T\n",
    "#             prediction = [training_models['detector_window_%s'%(last_event.prefix_length)][1].predict_proba(current_event), training_models['detector_window_%s'%(last_event.prefix_length)][1].classes_]\n",
    "#             modelid = training_models['detector_window_%s'%(last_event.prefix_length)][0]\n",
    "    case_bin.update_prediction((modelid, (prediction,ts)))        \n",
    "            \n",
    "    # Update training window and finish the case\n",
    "    if x['activity'] == 'End':\n",
    "        training_window.update_window({caseid: case_dict[caseid]})        \n",
    "        if training_window.retraining == training_window.retraining_count:            \n",
    "            training_models = training_stage(training_window, training_models)\n",
    "            prefix_wise_window = training_window.prefix_wise_window()\n",
    "            \n",
    "        resultdict[caseid] = case_dict[caseid]\n",
    "        case_dict.pop(caseid)\n",
    "\n",
    "        casecount +=1\n",
    "        for x in case_dict:\n",
    "            last_event = case_dict[x][-1]\n",
    "            modelid = 'None'\n",
    "            prediction = 'Not Available'\n",
    "\n",
    "            if len(training_window.getAllitems()) !=0:\n",
    "                prefix_wise_window = training_window.prefix_wise_window()\n",
    "                if 'window_%s'%(last_event.prefix_length) in list(prefix_wise_window.keys()) and 'detector_window_%s'%(last_event.prefix_length) in training_models.keys():\n",
    "                    modelid, prediction = predict_activity_proba(last_event)\n",
    "\n",
    "#                     feature_matrix = prefix_wise_window['window_%s'%(last_event.prefix_length)][0].columns.values\n",
    "#                     current_event = utils.readjustment_training(last_event.encoded, feature_matrix)\n",
    "#                     current_event = pd.Series(current_event).to_frame().T\n",
    "#                     prediction = [training_models['detector_window_%s'%(last_event.prefix_length)][1].predict_proba(current_event), training_models['detector_window_%s'%(last_event.prefix_length)][1].classes_]\n",
    "#                     modelid = training_models['detector_window_%s'%(last_event.prefix_length)][0]\n",
    "            case_dict[x][-1].update_prediction((modelid, (prediction,ts)))        \n",
    "        training_window.reset_retraining_count()\n",
    "    else:\n",
    "        case_dict[caseid].append(case_bin)\n",
    "\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e32ae563",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.642896564801534\n"
     ]
    }
   ],
   "source": [
    "print((end_time-start_time)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6934bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12af20db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for_confusion_matrix = {}\n",
    "\n",
    "counting_normal = 0\n",
    "\n",
    "for threshold in [0.01,0.05,0.1,0.15,0.2,0.25]:\n",
    "    global_true =[]\n",
    "    global_pred = []\n",
    "\n",
    "    for caseid in list(resultdict.keys()):\n",
    "\n",
    "        for_confusion_matrix[int(caseid)] =[]\n",
    "\n",
    "        prediction_list = []\n",
    "\n",
    "        df = original_df[original_df['Case ID'] == int(caseid)].reset_index(drop=True)\n",
    "        for pos, t in enumerate(resultdict['%s'%(caseid)]):\n",
    "            prediction_label = 'Normal'\n",
    "\n",
    "            predictions = list(t.predicted.values())[0][0]\n",
    "            predictions_proba = predictions[0][0]\n",
    "            predictions_value = list(predictions[1])\n",
    "            if predictions  == 'Not Available':\n",
    "                prediction_label = 'Not Available'\n",
    "            else:\n",
    "                if t.true_label in predictions_value:\n",
    "                    labelidx = predictions_value.index(t.true_label)\n",
    "\n",
    "                    if predictions_proba[labelidx] <threshold:\n",
    "                        prediction_label = 'Anomalous'\n",
    "                else:\n",
    "                    prediction_label = 'Anomalous'\n",
    "\n",
    "            if t.true_label != 'End':\n",
    "                prediction_list.append(prediction_label)\n",
    "\n",
    "\n",
    "        true_label_list = []\n",
    "\n",
    "        labellist = list(df['noise'])\n",
    "        actlist = list(df['Activity'])\n",
    "        for pos, t in enumerate(labellist):\n",
    "            if t == 'Start' or t == 'End':\n",
    "                continue\n",
    "            elif t == 'true':\n",
    "                true_label = 'Anomalous'\n",
    "            else:\n",
    "                true_label = 'Normal'\n",
    "            true_label_list.append(true_label)\n",
    "\n",
    "\n",
    "        for pos, p in enumerate(prediction_list):\n",
    "            global_pred.append(p)\n",
    "            global_true.append(true_label_list[pos])\n",
    "\n",
    "\n",
    "    saving_data = {'y_true':global_true, 'y_pred':global_pred}\n",
    "    import pickle\n",
    "    saving_file_name = file_name.split('/')[-1][:-4]\n",
    "\n",
    "    with open('./result/rf_thr%s_window%s_%s.pkl'%(threshold, window_size, saving_file_name), 'wb') as fp:\n",
    "        pickle.dump(saving_data, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5a6b27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
