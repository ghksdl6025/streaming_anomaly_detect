{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from river import stream,tree,metrics\n",
    "import utils\n",
    "from encoding import prefix_bin\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sliding_window\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import datetime, time\n",
    "import importlib\n",
    "importlib.reload(sliding_window)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "device = torch.device(\"cuda\")\n",
    "# Training\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './data/loan_baseline.pnml_noise_0.15_iteration_1_seed_614_sample.csv'\n",
    "\n",
    "\n",
    "dataset = stream.iter_csv(\n",
    "            file_name\n",
    "#             './data/loan_baseline.pnml_noise_0.15_iteration_1_seed_614_simple.csv',\n",
    "            )\n",
    "\n",
    "totallength = len(list(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stream.iter_csv(\n",
    "            file_name,\n",
    "            drop=['noise', 'lifecycle:transition', 'Variant', 'Variant index'],\n",
    "            )\n",
    "enctype = 'Index-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pair = {\n",
    "'Case ID':'caseid',\n",
    "'Activity':'activity',\n",
    "# 'Resource':'resource',\n",
    "'Complete Timestamp':'ts',\n",
    "}\n",
    "catatars= ['activity']#,'resource']\n",
    "\n",
    "case_dict ={}\n",
    "training_models ={}\n",
    "\n",
    "casecount = 0\n",
    "rowcounter = 0\n",
    "resultdict ={}\n",
    "acc_dict ={}\n",
    "prefix_wise_window = {}\n",
    "prediction_result = {}\n",
    "graceperiod_finish=0\n",
    "finishedcases = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window for training setting\n",
    "window_size = 100\n",
    "retraining_size = 20\n",
    "training_window = sliding_window.training_window(window_size,retraining_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module): # nn.Module 상속\n",
    "\n",
    "    def __init__(self, inputs):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        np_input = inputs.to_numpy()\n",
    "        np_reshape = np.reshape(np_input, (np_input.shape[0],1,np_input.shape[1]))\n",
    "        tensored_inputs = torch.tensor(np_reshape)\n",
    "        self.input_size = tensored_inputs.shape[2]\n",
    "        self.hidden_size =2* tensored_inputs.shape[2]\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=2, dropout=0.25, batch_first =False, bidirectional = False)\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(2*dimension, 1) #full connect\n",
    "\n",
    "    def forward(self, text, text_len):\n",
    "        text_emb = self.embedding(text)\n",
    "\n",
    "        out_forward = output[range(len(output)), text_len - 1, :self.dimension]\n",
    "        out_reverse = output[:, 0, self.dimension:]\n",
    "        out_reduced = torch.cat((out_forward, out_reverse), 1) #[range(len(output)), text_len -1 + 0 , self.dimension]\n",
    "        text_fea = self.drop(out_reduced)\n",
    "\n",
    "        text_fea = self.fc(text_fea)\n",
    "        text_fea = torch.squeeze(text_fea, 1)\n",
    "        text_out = torch.sigmoid(text_fea)\n",
    "\n",
    "        return text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMGenerator(nn.Module):\n",
    "    def __init__(self, seq_len, input_size, batch, hidden_size , num_layers, num_directions):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.h = torch.randn(num_layers * num_directions ,batch, hidden_size)\n",
    "        self.c = torch.randn(num_layers * num_directions ,batch, hidden_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=0.25, batch_first =True, bidirectional = False)\n",
    "\n",
    "\n",
    "        latent_vector_size =50 * batch\n",
    "        self.linear1 = nn.Linear(batch * seq_len *hidden_size, latent_vector_size)\n",
    "        # self.linear2 = nn.Linear(latent_vector_size,batch*seq_len*hidden_size)\n",
    "        self.linearHC = nn.Linear(num_layers *hidden_size *batch, latent_vector_size)\n",
    "        # self.linearHCO = nn.Linear(3*latent_vector_size,batch*seq_len*hidden_size )\n",
    "        self.linearHCO = nn.Linear( 3 *latent_vector_size ,batch *seq_len *input_size )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Define sigmoid activation and softmax output\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = x.view((1,x.size()[0], x.size()[1]))\n",
    "        # Pass the input tensor through each of our operations\n",
    "        # print(\"inputsize:\", x.size())\n",
    "        output, (h ,c) = self.lstm(x, (self.h, self.c))\n",
    "        # print(\"inputsize:\", x.size(),\"output size:\", output.size())\n",
    "        # print(\"h size:\", h.size(),\"c size:\", c.size())\n",
    "        self.h = h.detach()\n",
    "        self.c = c.detach()\n",
    "\n",
    "        # Executing Fully connected network\n",
    "        # print(\"The size of output:\", output.size(), h.size(), c.size())\n",
    "        u = output.reshape((output.size()[0 ] *output.size()[1 ] *output.size()[2]))\n",
    "        u = self.relu(self.linear1(u))\n",
    "        # print(\"The size of lninera1:\", u.size())\n",
    "        # u = self.linear2(u)\n",
    "\n",
    "        # Flating h and feeding it into a linear layer\n",
    "        uH = F.leaky_relu(self.linearHC(h.reshape((h.size()[0 ] *h.size()[1 ] *h.size()[2]))))\n",
    "        uC = F.leaky_relu(self.linearHC(c.reshape((c.size()[0 ] *c.size()[1 ] *c.size()[2]))))\n",
    "        uHCO = torch.cat((uH ,uC ,u))\n",
    "        uHCO = self.linearHCO(uHCO)\n",
    "        u= uHCO\n",
    "\n",
    "        # output = u.view((output.size()[0],output.size()[1],output.size()[2]))\n",
    "        output = u.view((output.size()[0],output.size()[1],self.input_size))\n",
    "        # print(\"output size finally:\", output.size())\n",
    "\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_progress(row_counting, total_length, interval=500):\n",
    "    if rowcounter%interval == 0:\n",
    "        print(round(rowcounter*100/totallength,2) ,'%', 'Case finished: %s'%(casecount), 'Running cases: %s'%(len(case_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % Case finished: 0 Running cases: 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'training_stage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SUHWAN~1\\AppData\\Local\\Temp/ipykernel_1880/3204940450.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mtraining_window\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mcaseid\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcase_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcaseid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtraining_window\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretraining\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtraining_window\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretraining_count\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0mtraining_models\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_window\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_models\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[0mprefix_wise_window\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_window\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefix_wise_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_stage' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for x,y in dataset:\n",
    "    display_progress(rowcounter, totallength)\n",
    "    rowcounter +=1\n",
    "    \n",
    "    utils.dictkey_chg(x, key_pair)\n",
    "    # Event stream change dictionary keys\n",
    "    x['ts'] = x['ts'][:-4]\n",
    "    \n",
    "    # Check label possible\n",
    "    \n",
    "    # Initialize case by prefix length\n",
    "    caseid = x['caseid']\n",
    "    x.pop('caseid')\n",
    "    \n",
    "    case_bin = prefix_bin(caseid, x)\n",
    "    \n",
    "    if caseid not in list(case_dict.keys()):\n",
    "        case_dict[caseid] = []\n",
    "        case_bin.set_prefix_length(1)\n",
    "        \n",
    "    elif caseid in finishedcases:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        case_bin.set_prefix_length(len(case_dict[caseid])+1)\n",
    "        case_bin.set_prev_enc(case_dict[caseid][-1])\n",
    "    \n",
    "    # Encode event and cases and add to DB\n",
    "    ts = case_bin.event['ts']\n",
    "    case_bin.update_encoded(catattrs=catatars,enctype=enctype)\n",
    "    \n",
    "    # Set current activity as outcome of previous event\n",
    "    if case_bin.prefix_length != 1:\n",
    "        case_bin.prev_enc.update_truelabel(x['activity'])\n",
    "\n",
    "    # First prediction for current event\n",
    "    \n",
    "    last_event = case_bin\n",
    "    modelid = 'None'\n",
    "    prediction = 'Not Available'\n",
    "\n",
    "    if len(training_window.getAllitems()) !=0:\n",
    "        if 'window_%s'%(last_event.prefix_length) in list(prefix_wise_window.keys()) and 'detector_window_%s'%(last_event.prefix_length) in training_models.keys():\n",
    "            modelid, prediction = predict_activity_proba(last_event)\n",
    "#             feature_matrix = prefix_wise_window['window_%s'%(last_event.prefix_length)][0].columns.values\n",
    "#             current_event = utils.readjustment_training(last_event.encoded, feature_matrix)\n",
    "#             current_event = pd.Series(current_event).to_frame().T\n",
    "#             prediction = [training_models['detector_window_%s'%(last_event.prefix_length)][1].predict_proba(current_event), training_models['detector_window_%s'%(last_event.prefix_length)][1].classes_]\n",
    "#             modelid = training_models['detector_window_%s'%(last_event.prefix_length)][0]\n",
    "    case_bin.update_prediction((modelid, (prediction,ts)))        \n",
    "            \n",
    "    # Update training window and finish the case\n",
    "    if x['activity'] == 'End':\n",
    "        training_window.update_window({caseid: case_dict[caseid]})        \n",
    "        if training_window.retraining == training_window.retraining_count:            \n",
    "            training_models = training_stage(training_window, training_models)\n",
    "            prefix_wise_window = training_window.prefix_wise_window()\n",
    "            \n",
    "        resultdict[caseid] = case_dict[caseid]\n",
    "        case_dict.pop(caseid)\n",
    "\n",
    "        casecount +=1\n",
    "        for x in case_dict:\n",
    "            last_event = case_dict[x][-1]\n",
    "            modelid = 'None'\n",
    "            prediction = 'Not Available'\n",
    "\n",
    "            if len(training_window.getAllitems()) !=0:\n",
    "                prefix_wise_window = training_window.prefix_wise_window()\n",
    "                if 'window_%s'%(last_event.prefix_length) in list(prefix_wise_window.keys()) and 'detector_window_%s'%(last_event.prefix_length) in training_models.keys():\n",
    "                    modelid, prediction = predict_activity_proba(last_event)\n",
    "\n",
    "#                     feature_matrix = prefix_wise_window['window_%s'%(last_event.prefix_length)][0].columns.values\n",
    "#                     current_event = utils.readjustment_training(last_event.encoded, feature_matrix)\n",
    "#                     current_event = pd.Series(current_event).to_frame().T\n",
    "#                     prediction = [training_models['detector_window_%s'%(last_event.prefix_length)][1].predict_proba(current_event), training_models['detector_window_%s'%(last_event.prefix_length)][1].classes_]\n",
    "#                     modelid = training_models['detector_window_%s'%(last_event.prefix_length)][0]\n",
    "            case_dict[x][-1].update_prediction((modelid, (prediction,ts)))        \n",
    "        training_window.reset_retraining_count()\n",
    "    else:\n",
    "        case_dict[caseid].append(case_bin)\n",
    "\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    duration_1  cumduration_1  activity_1 Start\n",
      "0            0              0                 1\n",
      "1            0              0                 1\n",
      "2            0              0                 1\n",
      "3            0              0                 1\n",
      "4            0              0                 1\n",
      "5            0              0                 1\n",
      "6            0              0                 1\n",
      "7            0              0                 1\n",
      "8            0              0                 1\n",
      "9            0              0                 1\n",
      "10           0              0                 1\n",
      "11           0              0                 1\n",
      "12           0              0                 1\n",
      "13           0              0                 1\n",
      "14           0              0                 1\n",
      "15           0              0                 1\n",
      "16           0              0                 1\n",
      "17           0              0                 1\n",
      "18           0              0                 1\n",
      "19           0              0                 1\n"
     ]
    }
   ],
   "source": [
    "pw_window = training_window.prefix_wise_window()\n",
    "for x in pw_window:\n",
    "#     print(pw_window[x])\n",
    "    print(pw_window[x][0])\n",
    "    break\n",
    "#     print(len(pw_window[x][1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
