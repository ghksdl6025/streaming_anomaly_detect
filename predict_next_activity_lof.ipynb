{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "814ef4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sliding_window' from 'C:\\\\Users\\\\suhwan\\\\Desktop\\\\Project\\\\coding\\\\streaming_anomaly_detect\\\\sliding_window.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from river import stream,tree,metrics\n",
    "import utils\n",
    "from encoding import prefix_bin\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sliding_window\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "import datetime, time\n",
    "import importlib\n",
    "importlib.reload(sliding_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f341163",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './data/loan_baseline.pnml_noise_0.15_iteration_1_seed_614_sample.csv'\n",
    "\n",
    "dataset = stream.iter_csv(\n",
    "            file_name\n",
    "#             './data/loan_baseline.pnml_noise_0.15_iteration_1_seed_614_simple.csv',\n",
    "            )\n",
    "\n",
    "totallength = len(list(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca01ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stream.iter_csv(\n",
    "            file_name,\n",
    "            drop=['noise', 'lifecycle:transition', 'Variant', 'Variant index'],\n",
    "            )\n",
    "enctype = 'Index-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73513009",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pair = {\n",
    "'Case ID':'caseid',\n",
    "'Activity':'activity',\n",
    "# 'Resource':'resource',\n",
    "'Complete Timestamp':'ts',\n",
    "}\n",
    "catatars= ['activity']#,'resource']\n",
    "\n",
    "case_dict ={}\n",
    "training_models ={}\n",
    "\n",
    "casecount = 0\n",
    "rowcounter = 0\n",
    "resultdict ={}\n",
    "acc_dict ={}\n",
    "prefix_wise_window = {}\n",
    "prediction_result = {}\n",
    "graceperiod_finish=0\n",
    "finishedcases = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed670cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window for training setting\n",
    "window_size = 50\n",
    "retraining_size = 10\n",
    "training_window = sliding_window.training_window(window_size,retraining_size)\n",
    "contamination = 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "655c132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_progress(row_counting, total_length, interval=500):\n",
    "    if rowcounter%interval == 0:\n",
    "        print(round(rowcounter*100/totallength,2) ,'%', 'Case finished: %s'%(casecount), 'Running cases: %s'%(len(case_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a70e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_stage(window, training_models):\n",
    "    '''\n",
    "    Manage training stage of streaming anomaly detection\n",
    "    ----------\n",
    "    Parameters\n",
    "    window: class training_window\n",
    "        Sliding window with training data\n",
    "    training_models: dict\n",
    "        Trained detector by prefix stored in. Default is randomforest\n",
    "    ----------\n",
    "    Return\n",
    "    training_models\n",
    "    '''\n",
    "    pw_window = window.prefix_wise_window()\n",
    "    for x in pw_window:\n",
    "        clf  = LocalOutlierFactor(n_neighbors=20, contamination= contamination)\n",
    "        \n",
    "        clf.fit(pw_window[x][0])\n",
    "        if 'detector_%s'%(x) not in training_models:\n",
    "            training_models['detector_%s'%(x)] =[0,0]\n",
    "        training_models['detector_%s'%(x)][0] += 1\n",
    "        training_models['detector_%s'%(x)][1] = clf\n",
    "    return training_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "184323ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_activity_proba(last_event):\n",
    "    '''\n",
    "    Predict next activity prediction \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    last_event: case_bin\n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    modelid, prediction\n",
    "    \n",
    "    '''\n",
    "    feature_matrix = prefix_wise_window['window_%s'%(last_event.prefix_length)][0].columns.values\n",
    "    current_event = utils.readjustment_training(last_event.encoded, feature_matrix)\n",
    "    current_event = pd.Series(current_event).to_frame().T\n",
    "    prediction = [training_models['detector_window_%s'%(last_event.prefix_length)][1].predict_proba(current_event), training_models['detector_window_%s'%(last_event.prefix_length)][1].classes_]\n",
    "    modelid = training_models['detector_window_%s'%(last_event.prefix_length)][0]\n",
    "\n",
    "    return modelid, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dedfa228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_event(case_bin):\n",
    "    '''\n",
    "    Generate start event before first event\n",
    "    '''\n",
    "    print(case_bin.event['ts'])\n",
    "    empty_data ={'activity':'Start signal', 'ts':datetime.datetime.strftime(case_bin.event['ts'], '%Y-%m-%d %H:%M:%S')}\n",
    "    start_event = prefix_bin(case_bin.caseid, empty_data)\n",
    "    start_event.set_prefix_length(0)\n",
    "    start_event.update_encoded(catattrs=catatars,enctype=enctype)\n",
    "    start_event.update_truelabel(case_bin.event['activity'])\n",
    "    return start_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c77ab56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.8 % Case finished: 28 Running cases: 2\n",
      "11.61 % Case finished: 59 Running cases: 2\n",
      "17.41 % Case finished: 91 Running cases: 2\n",
      "23.22 % Case finished: 120 Running cases: 2\n",
      "29.02 % Case finished: 147 Running cases: 2\n",
      "34.83 % Case finished: 179 Running cases: 1\n",
      "40.63 % Case finished: 210 Running cases: 2\n",
      "46.44 % Case finished: 241 Running cases: 2\n",
      "52.24 % Case finished: 272 Running cases: 1\n",
      "58.05 % Case finished: 300 Running cases: 2\n",
      "63.85 % Case finished: 333 Running cases: 1\n",
      "69.65 % Case finished: 364 Running cases: 2\n",
      "75.46 % Case finished: 394 Running cases: 2\n",
      "81.26 % Case finished: 426 Running cases: 2\n",
      "87.07 % Case finished: 456 Running cases: 2\n",
      "92.87 % Case finished: 489 Running cases: 2\n",
      "98.68 % Case finished: 517 Running cases: 2\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for x,y in dataset:\n",
    "    display_progress(rowcounter, totallength)\n",
    "    rowcounter +=1\n",
    "    \n",
    "    utils.dictkey_chg(x, key_pair)\n",
    "    # Event stream change dictionary keys\n",
    "    x['ts'] = x['ts'][:-4]\n",
    "    \n",
    "    # Check label possible\n",
    "    \n",
    "    # Initialize case by prefix length\n",
    "    caseid = x['caseid']\n",
    "    x.pop('caseid')\n",
    "    \n",
    "    case_bin = prefix_bin(caseid, x)\n",
    "    \n",
    "    if caseid not in list(case_dict.keys()):\n",
    "        case_dict[caseid] = []\n",
    "        case_bin.set_prefix_length(1)\n",
    "        \n",
    "    elif caseid in finishedcases:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        case_bin.set_prefix_length(len(case_dict[caseid])+1)\n",
    "        case_bin.set_prev_enc(case_dict[caseid][-1])\n",
    "    \n",
    "    # Encode event and cases and add to DB\n",
    "    ts = case_bin.event['ts']\n",
    "    case_bin.update_encoded(catattrs=catatars,enctype=enctype)\n",
    "    \n",
    "    # Set current activity as outcome of previous event\n",
    "    if case_bin.prefix_length != 1:\n",
    "        case_bin.prev_enc.update_truelabel(x['activity'])\n",
    "\n",
    "    # First prediction for current event\n",
    "    \n",
    "    last_event = case_bin\n",
    "    modelid = 'None'\n",
    "    prediction = 'Not Available'\n",
    "\n",
    "    if len(training_window.getAllitems()) !=0:\n",
    "        if 'window_%s'%(last_event.prefix_length) in list(prefix_wise_window.keys()) and 'detector_window_%s'%(last_event.prefix_length) in training_models.keys():\n",
    "#             modelid, prediction = predict_activity_proba(last_event)\n",
    "            feature_matrix = prefix_wise_window['window_%s'%(last_event.prefix_length)][0].columns.values\n",
    "            current_event = utils.readjustment_training(last_event.encoded, feature_matrix)\n",
    "            current_event = pd.Series(current_event).to_frame().T\n",
    "            prediction = [training_models['detector_window_%s'%(last_event.prefix_length)][1].predict(current_event)]\n",
    "            modelid = training_models['detector_window_%s'%(last_event.prefix_length)][0]\n",
    "    case_bin.update_prediction((modelid, (prediction,ts)))        \n",
    "            \n",
    "    # Update training window and finish the case\n",
    "    if x['activity'] == 'End':\n",
    "        training_window.update_window({caseid: case_dict[caseid]})        \n",
    "        if training_window.retraining == training_window.retraining_count:            \n",
    "            training_models = training_stage(training_window, training_models)\n",
    "            prefix_wise_window = training_window.prefix_wise_window()\n",
    "            \n",
    "        resultdict[caseid] = case_dict[caseid]\n",
    "        case_dict.pop(caseid)\n",
    "\n",
    "        casecount +=1\n",
    "        for x in case_dict:\n",
    "            last_event = case_dict[x][-1]\n",
    "            modelid = 'None'\n",
    "            prediction = 'Not Available'\n",
    "\n",
    "            if len(training_window.getAllitems()) !=0:\n",
    "                prefix_wise_window = training_window.prefix_wise_window()\n",
    "                if 'window_%s'%(last_event.prefix_length) in list(prefix_wise_window.keys()) and 'detector_window_%s'%(last_event.prefix_length) in training_models.keys():\n",
    "#                     modelid, prediction = predict_activity_proba(last_event)\n",
    "\n",
    "                    feature_matrix = prefix_wise_window['window_%s'%(last_event.prefix_length)][0].columns.values\n",
    "                    current_event = utils.readjustment_training(last_event.encoded, feature_matrix)\n",
    "                    current_event = pd.Series(current_event).to_frame().T\n",
    "                    prediction = [training_models['detector_window_%s'%(last_event.prefix_length)][1].predict(current_event)]\n",
    "                    modelid = training_models['detector_window_%s'%(last_event.prefix_length)][0]\n",
    "            case_dict[x][-1].update_prediction((modelid, (prediction,ts)))        \n",
    "        training_window.reset_retraining_count()\n",
    "    else:\n",
    "        case_dict[caseid].append(case_bin)\n",
    "\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "802c6c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9056624094645183\n"
     ]
    }
   ],
   "source": [
    "print((end_time-start_time)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52660788",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6697e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_confusion_matrix = {}\n",
    "\n",
    "global_true =[]\n",
    "global_pred = []\n",
    "counting_normal = 0\n",
    "for caseid in list(resultdict.keys()):\n",
    "\n",
    "    for_confusion_matrix[int(caseid)] =[]\n",
    "    \n",
    "    prediction_list = []\n",
    "    \n",
    "    df = original_df[original_df['Case ID'] == int(caseid)].reset_index(drop=True)\n",
    "    for pos, t in enumerate(resultdict['%s'%(caseid)]):\n",
    "        \n",
    "        predictions = list(t.predicted.values())[0][0]    \n",
    "        if predictions  == 'Not Available':\n",
    "            predictions_label = 'Not Available'\n",
    "        else:\n",
    "            predictions_label = predictions[0][0]\n",
    "\n",
    "        if predictions_label == 1:\n",
    "            predictions_label = 'Normal'\n",
    "        elif predictions_label == -1:\n",
    "            predictions_label = 'Anomalous'\n",
    "\n",
    "        if t.event['activity'] != 'Start':\n",
    "            prediction_list.append(predictions_label)\n",
    "            \n",
    "    true_label_list = []\n",
    "\n",
    "    labellist = list(df['noise'])\n",
    "    actlist = list(df['Activity'])\n",
    "    for pos, t in enumerate(labellist):\n",
    "        if t == 'Start' or t == 'End':\n",
    "            continue\n",
    "        elif t == 'true':\n",
    "            true_label = 'Anomalous'\n",
    "        else:\n",
    "            true_label = 'Normal'\n",
    "        true_label_list.append(true_label)\n",
    "\n",
    "    \n",
    "    for pos, p in enumerate(prediction_list):\n",
    "        global_pred.append(p)\n",
    "        global_true.append(true_label_list[pos])\n",
    "saving_data = {'y_true':global_true, 'y_pred':global_pred}\n",
    "import pickle\n",
    "saving_file_name = file_name.split('/')[-1][:-4]\n",
    "\n",
    "with open('./result/lof_cont%s_window%s_%s.pkl'%(contamination, window_size, saving_file_name), 'wb') as fp:\n",
    "    pickle.dump(saving_data, fp)\n",
    "#     print(caseid, len(true_label_list), len(prediction_list))\n",
    "\n",
    "#     for t in true_label_list:\n",
    "#         global_true.append(t)\n",
    "#     print(prediction_list)\n",
    "#     print(true_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b8dffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
