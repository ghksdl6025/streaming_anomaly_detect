{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44387976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sliding_window' from 'C:\\\\Users\\\\suhwan\\\\Desktop\\\\Project\\\\coding\\\\streaming_anomaly_detect\\\\sliding_window.py'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from river import stream,tree,metrics\n",
    "import utils\n",
    "from encoding import prefix_bin\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sliding_window\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import datetime, time\n",
    "import importlib\n",
    "importlib.reload(sliding_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5f424c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stream.iter_csv(\n",
    "            './data/loan_baseline.pnml_noise_0.15_iteration_1_seed_614_simple.csv',\n",
    "            )\n",
    "\n",
    "totallength = len(list(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bd08beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stream.iter_csv(\n",
    "            './data/loan_baseline.pnml_noise_0.15_iteration_1_seed_614_simple.csv',\n",
    "            drop=['noise', 'lifecycle:transition', 'Variant', 'Variant index'],\n",
    "            )\n",
    "enctype = 'Index-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b7654d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pair = {\n",
    "'Case ID':'caseid',\n",
    "'Activity':'activity',\n",
    "# 'Resource':'resource',\n",
    "'Complete Timestamp':'ts',\n",
    "}\n",
    "catatars= ['activity']#,'resource']\n",
    "\n",
    "case_dict ={}\n",
    "training_models ={}\n",
    "\n",
    "casecount = 0\n",
    "rowcounter = 0\n",
    "resultdict ={}\n",
    "acc_dict ={}\n",
    "prefix_wise_window = {}\n",
    "prediction_result = {}\n",
    "graceperiod_finish=0\n",
    "finishedcases = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0f457584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window for training setting\n",
    "window_size = 50\n",
    "retraining_size = 10\n",
    "training_window = sliding_window.training_window(window_size,retraining_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2bef05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_progress(row_counting, total_length, interval=500):\n",
    "    if rowcounter%interval == 0:\n",
    "        print(round(rowcounter*100/totallength,2) ,'%', 'Case finished: %s'%(casecount), 'Running cases: %s'%(len(case_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9dc27209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_stage(window, training_models):\n",
    "    '''\n",
    "    Manage training stage of streaming anomaly detection\n",
    "    ----------\n",
    "    Parameters\n",
    "    window: class training_window\n",
    "        Sliding window with training data\n",
    "    training_models: dict\n",
    "        Trained detector by prefix stored in. Default is randomforest\n",
    "    ----------\n",
    "    Return\n",
    "    training_models\n",
    "    '''\n",
    "    pw_window = window.prefix_wise_window()\n",
    "    for x in pw_window:\n",
    "        clf  = RandomForestClassifier(max_depth=10)\n",
    "        training_x = pw_window[x][0]\n",
    "        training_y = pw_window[x][1]\n",
    "        \n",
    "        clf.fit(pw_window[x][0],pw_window[x][1])\n",
    "        if 'detector_%s'%(x) not in training_models:\n",
    "            training_models['detector_%s'%(x)] =[0,0]\n",
    "        training_models['detector_%s'%(x)][0] += 1\n",
    "        training_models['detector_%s'%(x)][1] = clf\n",
    "    return training_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4594b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_activity_proba(last_event):\n",
    "    '''\n",
    "    Predict next activity prediction \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    last_event: case_bin\n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    modelid, prediction\n",
    "    \n",
    "    '''\n",
    "    feature_matrix = prefix_wise_window['window_%s'%(last_event.prefix_length)][0].columns.values\n",
    "    current_event = utils.readjustment_training(last_event.encoded, feature_matrix)\n",
    "    current_event = pd.Series(current_event).to_frame().T\n",
    "    prediction = [training_models['detector_window_%s'%(last_event.prefix_length)][1].predict_proba(current_event), training_models['detector_window_%s'%(last_event.prefix_length)][1].classes_]\n",
    "    modelid = training_models['detector_window_%s'%(last_event.prefix_length)][0]\n",
    "\n",
    "    return modelid, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0ea7b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_event(case_bin):\n",
    "    '''\n",
    "    Generate start event before first event\n",
    "    '''\n",
    "    print(case_bin.event['ts'])\n",
    "    empty_data ={'activity':'Start signal', 'ts':datetime.datetime.strftime(case_bin.event['ts'], '%Y-%m-%d %H:%M:%S')}\n",
    "    start_event = prefix_bin(case_bin.caseid, empty_data)\n",
    "    start_event.set_prefix_length(0)\n",
    "    start_event.update_encoded(catattrs=catatars,enctype=enctype)\n",
    "    start_event.update_truelabel(case_bin.event['activity'])\n",
    "    return start_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0e7ddd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<encoding.prefix_bin object at 0x000001F8CF2FD700>\n"
     ]
    }
   ],
   "source": [
    "print(case_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ebdc5a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % Case finished: 0 Running cases: 0\n",
      "5.8 % Case finished: 29 Running cases: 1\n",
      "11.61 % Case finished: 60 Running cases: 1\n",
      "17.41 % Case finished: 92 Running cases: 1\n",
      "23.22 % Case finished: 121 Running cases: 1\n",
      "29.02 % Case finished: 148 Running cases: 1\n",
      "34.83 % Case finished: 180 Running cases: 0\n",
      "40.63 % Case finished: 211 Running cases: 1\n",
      "46.44 % Case finished: 242 Running cases: 1\n",
      "52.24 % Case finished: 273 Running cases: 0\n",
      "58.05 % Case finished: 301 Running cases: 1\n",
      "63.85 % Case finished: 334 Running cases: 0\n",
      "69.65 % Case finished: 365 Running cases: 1\n",
      "75.46 % Case finished: 395 Running cases: 1\n",
      "81.26 % Case finished: 427 Running cases: 1\n",
      "87.07 % Case finished: 457 Running cases: 1\n",
      "92.87 % Case finished: 490 Running cases: 1\n",
      "98.68 % Case finished: 518 Running cases: 1\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for x,y in dataset:\n",
    "    display_progress(rowcounter, totallength)\n",
    "    rowcounter +=1\n",
    "    \n",
    "    utils.dictkey_chg(x, key_pair)\n",
    "    # Event stream change dictionary keys\n",
    "    x['ts'] = x['ts'][:-4]\n",
    "    \n",
    "    # Check label possible\n",
    "    \n",
    "    # Initialize case by prefix length\n",
    "    caseid = x['caseid']\n",
    "    x.pop('caseid')\n",
    "    \n",
    "    case_bin = prefix_bin(caseid, x)\n",
    "    \n",
    "    if caseid not in list(case_dict.keys()):\n",
    "        case_dict[caseid] = []\n",
    "        case_bin.set_prefix_length(1)\n",
    "        \n",
    "    elif caseid in finishedcases:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        case_bin.set_prefix_length(len(case_dict[caseid])+1)\n",
    "        case_bin.set_prev_enc(case_dict[caseid][-1])\n",
    "    \n",
    "    # Encode event and cases and add to DB\n",
    "    ts = case_bin.event['ts']\n",
    "    case_bin.update_encoded(catattrs=catatars,enctype=enctype)\n",
    "    \n",
    "    # Set current activity as outcome of previous event\n",
    "    if case_bin.prefix_length != 1:\n",
    "        case_bin.prev_enc.update_truelabel(x['activity'])\n",
    "\n",
    "    # First prediction for current event\n",
    "    \n",
    "    last_event = case_bin\n",
    "    modelid = 'None'\n",
    "    prediction = 'Not Available'\n",
    "\n",
    "    if len(training_window.getAllitems()) !=0:\n",
    "        if 'window_%s'%(last_event.prefix_length) in list(prefix_wise_window.keys()) and 'detector_window_%s'%(last_event.prefix_length) in training_models.keys():\n",
    "            modelid, prediction = predict_activity_proba(last_event)\n",
    "#             feature_matrix = prefix_wise_window['window_%s'%(last_event.prefix_length)][0].columns.values\n",
    "#             current_event = utils.readjustment_training(last_event.encoded, feature_matrix)\n",
    "#             current_event = pd.Series(current_event).to_frame().T\n",
    "#             prediction = [training_models['detector_window_%s'%(last_event.prefix_length)][1].predict_proba(current_event), training_models['detector_window_%s'%(last_event.prefix_length)][1].classes_]\n",
    "#             modelid = training_models['detector_window_%s'%(last_event.prefix_length)][0]\n",
    "    case_bin.update_prediction((modelid, (prediction,ts)))        \n",
    "            \n",
    "    # Update training window and finish the case\n",
    "    if x['activity'] == 'End':\n",
    "        training_window.update_window({caseid: case_dict[caseid]})        \n",
    "        if training_window.retraining == training_window.retraining_count:            \n",
    "            training_models = training_stage(training_window, training_models)\n",
    "            prefix_wise_window = training_window.prefix_wise_window()\n",
    "            \n",
    "        resultdict[caseid] = case_dict[caseid]\n",
    "        case_dict.pop(caseid)\n",
    "\n",
    "        casecount +=1\n",
    "        for x in case_dict:\n",
    "            last_event = case_dict[x][-1]\n",
    "            modelid = 'None'\n",
    "            prediction = 'Not Available'\n",
    "\n",
    "            if len(training_window.getAllitems()) !=0:\n",
    "                prefix_wise_window = training_window.prefix_wise_window()\n",
    "                if 'window_%s'%(last_event.prefix_length) in list(prefix_wise_window.keys()) and 'detector_window_%s'%(last_event.prefix_length) in training_models.keys():\n",
    "                    modelid, prediction = predict_activity_proba(last_event)\n",
    "\n",
    "#                     feature_matrix = prefix_wise_window['window_%s'%(last_event.prefix_length)][0].columns.values\n",
    "#                     current_event = utils.readjustment_training(last_event.encoded, feature_matrix)\n",
    "#                     current_event = pd.Series(current_event).to_frame().T\n",
    "#                     prediction = [training_models['detector_window_%s'%(last_event.prefix_length)][1].predict_proba(current_event), training_models['detector_window_%s'%(last_event.prefix_length)][1].classes_]\n",
    "#                     modelid = training_models['detector_window_%s'%(last_event.prefix_length)][0]\n",
    "            case_dict[x][-1].update_prediction((modelid, (prediction,ts)))        \n",
    "        training_window.reset_retraining_count()\n",
    "    else:\n",
    "        case_dict[caseid].append(case_bin)\n",
    "\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e32ae563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8872692465782164\n"
     ]
    }
   ],
   "source": [
    "print((end_time-start_time)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6934bb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       Case ID                                    Activity  \\\n",
      "7900      484                                       Start   \n",
      "7901      484      start_event_Loan  application received   \n",
      "7902      484       Check  application  form completeness   \n",
      "7903      484                        Check credit history   \n",
      "7904      484                            Assess loan risk   \n",
      "7905      484                           Appraise property   \n",
      "7906      484       Check  application  form completeness   \n",
      "7907      484                          Assess eligibility   \n",
      "7908      484  Check if home insurance quote is requested   \n",
      "7909      484                        Send acceptance pack   \n",
      "7910      484                  Verify repayment agreement   \n",
      "7911      484                          Cancel application   \n",
      "7912      484        end_event_Loan  application canceled   \n",
      "7913      484                                         End   \n",
      "\n",
      "           Complete Timestamp      Variant  Variant index  \\\n",
      "7900  2018-12-03 05:45:56.054  Variant 438            438   \n",
      "7901  2018-12-03 05:45:56.054  Variant 438            438   \n",
      "7902  2018-12-03 07:25:55.592  Variant 438            438   \n",
      "7903  2018-12-03 08:45:52.919  Variant 438            438   \n",
      "7904  2018-12-03 10:30:20.485  Variant 438            438   \n",
      "7905  2018-12-03 11:01:27.416  Variant 438            438   \n",
      "7906  2018-12-03 11:01:27.416  Variant 438            438   \n",
      "7907  2018-12-03 12:30:54.163  Variant 438            438   \n",
      "7908  2018-12-03 12:41:34.682  Variant 438            438   \n",
      "7909  2018-12-03 12:53:35.080  Variant 438            438   \n",
      "7910  2018-12-03 15:15:57.174  Variant 438            438   \n",
      "7911  2018-12-03 15:55:23.689  Variant 438            438   \n",
      "7912  2018-12-03 16:04:32.487  Variant 438            438   \n",
      "7913  2018-12-03 16:04:32.487  Variant 438            438   \n",
      "\n",
      "     lifecycle:transition  noise  \n",
      "7900                Start  Start  \n",
      "7901             complete    NaN  \n",
      "7902             complete    NaN  \n",
      "7903             complete    NaN  \n",
      "7904             complete    NaN  \n",
      "7905             complete    NaN  \n",
      "7906                  NaN   true  \n",
      "7907             complete    NaN  \n",
      "7908             complete    NaN  \n",
      "7909             complete    NaN  \n",
      "7910             complete    NaN  \n",
      "7911             complete    NaN  \n",
      "7912             complete    NaN  \n",
      "7913                  End    End  >\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/loan_baseline.pnml_noise_0.15_iteration_1_seed_614_simple.csv')\n",
    "df = df[df['Case ID'] == 484]\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "159cbbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start start_event_Loan  application received ['Approve application', 'Check  application  form completeness', 'Return application back to applicant', 'Send acceptance pack', 'Send home insurance quote', 'end_event_Loan  application canceled', 'start_event_Loan  application received']\n",
      "start_event_Loan  application received Check  application  form completeness ['Assess loan risk', 'Check  application  form completeness', 'end_event_Loan  application approved', 'start_event_Loan  application received']\n",
      "Check  application  form completeness Check credit history ['Appraise property', 'Approve application', 'Check  application  form completeness', 'Check credit history', 'Reject application', 'Return application back to applicant', 'Send home insurance quote', 'end_event_Loan  application canceled', 'start_event_Loan  application received']\n",
      "Check credit history Assess loan risk ['Appraise property', 'Approve application', 'Assess eligibility', 'Assess loan risk', 'Check  application  form completeness', 'Check credit history', 'Receive updated application', 'Return application back to applicant', 'Send acceptance pack', 'Verify repayment agreement', 'end_event_Loan  application approved', 'end_event_Loan  application canceled']\n",
      "Assess loan risk Appraise property ['Appraise property', 'Assess loan risk', 'Cancel application', 'Check  application  form completeness', 'Check credit history', 'Receive updated application', 'Return application back to applicant', 'Send home insurance quote', 'end_event_Loan  application approved', 'end_event_Loan application rejected']\n",
      "Appraise property Check  application  form completeness ['Appraise property', 'Assess eligibility', 'Assess loan risk', 'Check  application  form completeness', 'Check credit history', 'Check if home insurance quote is requested', 'Receive updated application', 'Reject application', 'Return application back to applicant', 'Send home insurance quote', 'Verify repayment agreement', 'end_event_Loan  application approved', 'start_event_Loan  application received']\n",
      "Check  application  form completeness Assess eligibility ['Appraise property', 'Assess eligibility', 'Assess loan risk', 'Cancel application', 'Check  application  form completeness', 'Check credit history', 'Check if home insurance quote is requested', 'Receive updated application', 'Reject application', 'Return application back to applicant', 'end_event_Loan  application approved']\n",
      "Assess eligibility Check if home insurance quote is requested ['Appraise property', 'Assess eligibility', 'Assess loan risk', 'Check  application  form completeness', 'Check credit history', 'Check if home insurance quote is requested', 'Receive updated application', 'Reject application', 'Return application back to applicant', 'Send acceptance pack', 'Send home insurance quote', 'Verify repayment agreement', 'end_event_Loan application rejected', 'start_event_Loan  application received']\n",
      "Check if home insurance quote is requested Send acceptance pack ['Appraise property', 'Assess eligibility', 'Assess loan risk', 'Check  application  form completeness', 'Check credit history', 'Check if home insurance quote is requested', 'End', 'Receive updated application', 'Reject application', 'Return application back to applicant', 'Send acceptance pack', 'Send home insurance quote', 'Verify repayment agreement', 'end_event_Loan application rejected', 'start_event_Loan  application received']\n",
      "Send acceptance pack Verify repayment agreement ['Appraise property', 'Assess eligibility', 'Assess loan risk', 'Cancel application', 'Check  application  form completeness', 'Check credit history', 'Check if home insurance quote is requested', 'End', 'Receive updated application', 'Reject application', 'Return application back to applicant', 'Send acceptance pack', 'Send home insurance quote', 'Verify repayment agreement', 'end_event_Loan  application approved', 'end_event_Loan  application canceled', 'end_event_Loan application rejected']\n",
      "Verify repayment agreement Cancel application ['Appraise property', 'Approve application', 'Assess eligibility', 'Assess loan risk', 'Cancel application', 'Check  application  form completeness', 'Check credit history', 'End', 'Receive updated application', 'Reject application', 'Send acceptance pack', 'Send home insurance quote', 'Verify repayment agreement', 'end_event_Loan  application canceled', 'end_event_Loan application rejected']\n",
      "Cancel application end_event_Loan  application canceled ['Appraise property', 'Approve application', 'Assess eligibility', 'Cancel application', 'Check  application  form completeness', 'Check credit history', 'Check if home insurance quote is requested', 'End', 'Reject application', 'Return application back to applicant', 'Send home insurance quote', 'Verify repayment agreement', 'end_event_Loan  application approved']\n",
      "end_event_Loan  application canceled End ['Appraise property', 'Assess eligibility', 'Assess loan risk', 'Cancel application', 'Check credit history', 'Check if home insurance quote is requested', 'End', 'Receive updated application', 'Return application back to applicant', 'Send acceptance pack', 'Verify repayment agreement', 'end_event_Loan  application approved', 'end_event_Loan  application canceled', 'end_event_Loan application rejected', 'start_event_Loan  application received']\n",
      "['Normal', 'Normal', 'Anomalous', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Anomalous', 'Normal']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'End'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(resultdict['484']))\n",
    "prediction_list = []\n",
    "for pos, t in enumerate(resultdict['484']):\n",
    "    prediction_correct= 'Normal'\n",
    "\n",
    "    predictions = list(t.predicted.values())[0][0]\n",
    "    predictions_proba = predictions[0][0]\n",
    "    predictions_label = list(predictions[1])\n",
    "    print(t.event['activity'], list(df['Activity'])[pos+1], predictions_label)\n",
    "\n",
    "    if t.true_label in predictions_label:\n",
    "        labelidx = predictions_label.index(t.true_label)\n",
    "        \n",
    "        if predictions_proba[labelidx] <0.01:\n",
    "            prediction_correct = 'Anomalous'\n",
    "    else:\n",
    "        prediction_correct = 'Anomalous'\n",
    "\n",
    "    prediction_list.append(prediction_correct)\n",
    "\n",
    "print(prediction_list)\n",
    "list(df['Activity'])[pos+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3ab7dac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check credit history Anomalous Normal\n",
      "Check  application  form completeness Normal Anomalous\n",
      "end_event_Loan  application canceled Anomalous Normal\n",
      "10 3 13\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "incorrect = 0\n",
    "total =0\n",
    "for pos, t in enumerate(prediction_list):\n",
    "    \n",
    "    if list(df['noise'])[pos+1] == 'true':\n",
    "        true_label = 'Anomalous'\n",
    "        \n",
    "    elif list(df['noise'])[pos+1] == 'End':\n",
    "        true_label = 'Normal'\n",
    "       \n",
    "    else:\n",
    "        true_label = 'Normal'\n",
    "        \n",
    "    if t == true_label:\n",
    "        correct +=1\n",
    "    else:\n",
    "        print(list(df['Activity'])[pos+1], t, true_label)\n",
    "        incorrect +=1\n",
    "    total +=1\n",
    "print(correct, incorrect, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f3fac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdict2 ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06a5681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in resultdict.keys():\n",
    "    resultdict2[t] ={}\n",
    "    for x in resultdict[t]:\n",
    "        resultdict2[t]['Event_%s'%(x.prefix_length)] =[x.predicted, x.true_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "93d04960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(sliding_window)\n",
    "pw_window = training_window.prefix_wise_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b8ec8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('result_rf.pkl', 'wb') as fp:\n",
    "    pickle.dump(resultdict2, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "18c7088d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['duration_1' 'cumduration_1' 'activity_1 A_Create Application'\n",
      " 'resource_1 User_5' 'duration_2' 'cumduration_2'\n",
      " 'activity_2 W_Complete application' 'resource_2 User_5'\n",
      " 'resource_1 User_1' 'activity_2 A_Submitted' 'resource_2 User_1'\n",
      " 'resource_1 User_47' 'resource_2 User_47' 'resource_1 User_3'\n",
      " 'activity_2 A_Concept' 'resource_2 User_3' 'resource_1 User_28'\n",
      " 'resource_2 User_28' 'resource_1 User_23' 'resource_2 User_23'\n",
      " 'resource_1 User_16' 'resource_2 User_16' 'resource_1 User_76'\n",
      " 'resource_2 User_76' 'resource_1 User_45' 'resource_2 User_45'\n",
      " 'resource_1 User_37' 'resource_2 User_37' 'resource_1 User_52'\n",
      " 'resource_2 User_52' 'resource_1 User_4' 'resource_2 User_4'\n",
      " 'resource_1 User_10' 'resource_2 User_10' 'resource_1 User_51'\n",
      " 'resource_2 User_51']\n"
     ]
    }
   ],
   "source": [
    "print(pw_window['window_2'][0].columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7a0439d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_models = training_stage(training_window, training_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0c453149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A_Accepted' 'O_Create Offer' 'O_Created' 'W_Complete application']\n",
      "[[0.06 0.   0.91 0.03]]\n",
      "['O_Created']\n"
     ]
    }
   ],
   "source": [
    "print(clf.classes_)\n",
    "print(clf.predict_proba(x_train.loc[19:]))\n",
    "print(clf.predict(x_train.loc[19:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "27417bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(x_train,y_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
