{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44387976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sliding_window' from 'C:\\\\Users\\\\suhwan\\\\Desktop\\\\Project\\\\coding\\\\streaming_anomaly_detect\\\\sliding_window.py'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from river import stream,tree,metrics\n",
    "import utils\n",
    "from encoding import prefix_bin\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sliding_window\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import datetime, time\n",
    "import importlib\n",
    "importlib.reload(sliding_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5f424c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stream.iter_csv(\n",
    "            './data/loan_baseline.pnml_noise_0.15_iteration_1_seed_614_simple.csv'\n",
    "            )\n",
    "\n",
    "totallength = len(list(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bd08beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stream.iter_csv(\n",
    "            './data/loan_baseline.pnml_noise_0.15_iteration_1_seed_614_simple.csv',\n",
    "            drop=['noise', 'lifecycle:transition', 'Variant', 'Variant index'],\n",
    "            )\n",
    "enctype = 'Index-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b7654d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_pair = {\n",
    "'Case ID':'caseid',\n",
    "'Activity':'activity',\n",
    "# 'Resource':'resource',\n",
    "'Complete Timestamp':'ts',\n",
    "}\n",
    "catatars= ['activity']#,'resource']\n",
    "\n",
    "case_dict ={}\n",
    "training_models ={}\n",
    "\n",
    "casecount = 0\n",
    "rowcounter = 0\n",
    "resultdict ={}\n",
    "acc_dict ={}\n",
    "prefix_wise_window = {}\n",
    "prediction_result = {}\n",
    "graceperiod_finish=0\n",
    "finishedcases = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0f457584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding window for training setting\n",
    "window_size = 50\n",
    "retraining_size = 10\n",
    "training_window = sliding_window.training_window(window_size,retraining_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2bef05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_progress(row_counting, total_length, interval=500):\n",
    "    if rowcounter%interval == 0:\n",
    "        print(round(rowcounter*100/totallength,2) ,'%', 'Case finished: %s'%(casecount), 'Running cases: %s'%(len(case_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9dc27209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_stage(window, training_models):\n",
    "    '''\n",
    "    Manage training stage of streaming anomaly detection\n",
    "    ----------\n",
    "    Parameters\n",
    "    window: class training_window\n",
    "        Sliding window with training data\n",
    "    training_models: dict\n",
    "        Trained detector by prefix stored in. Default is randomforest\n",
    "    ----------\n",
    "    Return\n",
    "    training_models\n",
    "    '''\n",
    "    pw_window = window.prefix_wise_window()\n",
    "    for x in pw_window:\n",
    "        clf  = RandomForestClassifier()\n",
    "        training_x = pw_window[x][0]\n",
    "        training_y = pw_window[x][1]\n",
    "        \n",
    "        clf.fit(pw_window[x][0],pw_window[x][1])\n",
    "        if 'detector_%s'%(x) not in training_models:\n",
    "            training_models['detector_%s'%(x)] =[0,0]\n",
    "        training_models['detector_%s'%(x)][0] += 1\n",
    "        training_models['detector_%s'%(x)][1] = clf\n",
    "    return training_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4594b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_activity_proba(last_event):\n",
    "    '''\n",
    "    Predict next activity prediction \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    last_event: case_bin\n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    modelid, prediction\n",
    "    \n",
    "    '''\n",
    "    feature_matrix = prefix_wise_window['window_%s'%(last_event.prefix_length)][0].columns.values\n",
    "    current_event = utils.readjustment_training(last_event.encoded, feature_matrix)\n",
    "    current_event = pd.Series(current_event).to_frame().T\n",
    "    prediction = [training_models['detector_window_%s'%(last_event.prefix_length)][1].predict_proba(current_event), training_models['detector_window_%s'%(last_event.prefix_length)][1].classes_]\n",
    "    modelid = training_models['detector_window_%s'%(last_event.prefix_length)][0]\n",
    "\n",
    "    return modelid, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0ea7b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_event(case_bin):\n",
    "    '''\n",
    "    Generate start event before first event\n",
    "    '''\n",
    "    print(case_bin.event['ts'])\n",
    "    empty_data ={'activity':'Start signal', 'ts':datetime.datetime.strftime(case_bin.event['ts'], '%Y-%m-%d %H:%M:%S')}\n",
    "    start_event = prefix_bin(case_bin.caseid, empty_data)\n",
    "    start_event.set_prefix_length(0)\n",
    "    start_event.update_encoded(catattrs=catatars,enctype=enctype)\n",
    "    start_event.update_truelabel(case_bin.event['activity'])\n",
    "    return start_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ebdc5a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % Case finished: 0 Running cases: 0\n",
      "5.8 % Case finished: 29 Running cases: 1\n",
      "11.61 % Case finished: 60 Running cases: 1\n",
      "17.41 % Case finished: 92 Running cases: 1\n",
      "23.22 % Case finished: 121 Running cases: 1\n",
      "29.02 % Case finished: 148 Running cases: 1\n",
      "34.83 % Case finished: 180 Running cases: 0\n",
      "40.63 % Case finished: 211 Running cases: 1\n",
      "46.44 % Case finished: 242 Running cases: 1\n",
      "52.24 % Case finished: 273 Running cases: 0\n",
      "58.05 % Case finished: 301 Running cases: 1\n",
      "63.85 % Case finished: 334 Running cases: 0\n",
      "69.65 % Case finished: 365 Running cases: 1\n",
      "75.46 % Case finished: 395 Running cases: 1\n",
      "81.26 % Case finished: 427 Running cases: 1\n",
      "87.07 % Case finished: 457 Running cases: 1\n",
      "92.87 % Case finished: 490 Running cases: 1\n",
      "98.68 % Case finished: 518 Running cases: 1\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for x,y in dataset:\n",
    "    display_progress(rowcounter, totallength)\n",
    "    rowcounter +=1\n",
    "    \n",
    "    utils.dictkey_chg(x, key_pair)\n",
    "    # Event stream change dictionary keys\n",
    "    x['ts'] = x['ts'][:-4]\n",
    "    \n",
    "    # Check label possible\n",
    "    \n",
    "    # Initialize case by prefix length\n",
    "    caseid = x['caseid']\n",
    "    x.pop('caseid')\n",
    "    \n",
    "    case_bin = prefix_bin(caseid, x)\n",
    "    \n",
    "    if caseid not in list(case_dict.keys()):\n",
    "        case_dict[caseid] = []\n",
    "        case_bin.set_prefix_length(1)\n",
    "        \n",
    "    elif caseid in finishedcases:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        case_bin.set_prefix_length(len(case_dict[caseid])+1)\n",
    "        case_bin.set_prev_enc(case_dict[caseid][-1])\n",
    "    \n",
    "    # Encode event and cases and add to DB\n",
    "    ts = case_bin.event['ts']\n",
    "    case_bin.update_encoded(catattrs=catatars,enctype=enctype)\n",
    "    \n",
    "    # Set current activity as outcome of previous event\n",
    "    if case_bin.prefix_length != 1:\n",
    "        case_bin.prev_enc.update_truelabel(x['activity'])\n",
    "\n",
    "    # First prediction for current event\n",
    "    \n",
    "    last_event = case_bin\n",
    "    modelid = 'None'\n",
    "    prediction = 'Not Available'\n",
    "\n",
    "    if len(training_window.getAllitems()) !=0:\n",
    "        if 'window_%s'%(last_event.prefix_length) in list(prefix_wise_window.keys()) and 'detector_window_%s'%(last_event.prefix_length) in training_models.keys():\n",
    "            modelid, prediction = predict_activity_proba(last_event)\n",
    "#             feature_matrix = prefix_wise_window['window_%s'%(last_event.prefix_length)][0].columns.values\n",
    "#             current_event = utils.readjustment_training(last_event.encoded, feature_matrix)\n",
    "#             current_event = pd.Series(current_event).to_frame().T\n",
    "#             prediction = [training_models['detector_window_%s'%(last_event.prefix_length)][1].predict_proba(current_event), training_models['detector_window_%s'%(last_event.prefix_length)][1].classes_]\n",
    "#             modelid = training_models['detector_window_%s'%(last_event.prefix_length)][0]\n",
    "    case_bin.update_prediction((modelid, (prediction,ts)))        \n",
    "            \n",
    "    # Update training window and finish the case\n",
    "    if x['activity'] == 'End':\n",
    "        training_window.update_window({caseid: case_dict[caseid]})        \n",
    "        if training_window.retraining == training_window.retraining_count:            \n",
    "            training_models = training_stage(training_window, training_models)\n",
    "            prefix_wise_window = training_window.prefix_wise_window()\n",
    "            \n",
    "        resultdict[caseid] = case_dict[caseid]\n",
    "        case_dict.pop(caseid)\n",
    "\n",
    "        casecount +=1\n",
    "        for x in case_dict:\n",
    "            last_event = case_dict[x][-1]\n",
    "            modelid = 'None'\n",
    "            prediction = 'Not Available'\n",
    "\n",
    "            if len(training_window.getAllitems()) !=0:\n",
    "                prefix_wise_window = training_window.prefix_wise_window()\n",
    "                if 'window_%s'%(last_event.prefix_length) in list(prefix_wise_window.keys()) and 'detector_window_%s'%(last_event.prefix_length) in training_models.keys():\n",
    "                    modelid, prediction = predict_activity_proba(last_event)\n",
    "\n",
    "#                     feature_matrix = prefix_wise_window['window_%s'%(last_event.prefix_length)][0].columns.values\n",
    "#                     current_event = utils.readjustment_training(last_event.encoded, feature_matrix)\n",
    "#                     current_event = pd.Series(current_event).to_frame().T\n",
    "#                     prediction = [training_models['detector_window_%s'%(last_event.prefix_length)][1].predict_proba(current_event), training_models['detector_window_%s'%(last_event.prefix_length)][1].classes_]\n",
    "#                     modelid = training_models['detector_window_%s'%(last_event.prefix_length)][0]\n",
    "            case_dict[x][-1].update_prediction((modelid, (prediction,ts)))        \n",
    "        training_window.reset_retraining_count()\n",
    "    else:\n",
    "        case_dict[caseid].append(case_bin)\n",
    "\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e32ae563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6343265891075136\n"
     ]
    }
   ],
   "source": [
    "print((end_time-start_time)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6934bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('./data/loan_baseline.pnml_noise_0.15_iteration_1_seed_614_simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "12af20db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9 9\n",
      "1 12 12\n",
      "2 10 10\n",
      "3 14 14\n",
      "4 17 17\n",
      "5 15 15\n",
      "6 11 11\n",
      "7 14 14\n",
      "8 19 19\n",
      "9 14 14\n",
      "10 9 9\n",
      "11 14 14\n",
      "12 12 12\n",
      "13 8 8\n",
      "14 18 18\n",
      "15 15 15\n",
      "16 18 18\n",
      "17 19 19\n",
      "18 27 27\n",
      "19 32 32\n",
      "20 12 12\n",
      "21 10 10\n",
      "22 9 9\n",
      "23 19 19\n",
      "24 13 13\n",
      "25 17 17\n",
      "26 14 14\n",
      "27 9 9\n",
      "28 22 22\n",
      "29 35 35\n",
      "30 26 26\n",
      "31 8 8\n",
      "32 10 10\n",
      "33 9 9\n",
      "34 8 8\n",
      "35 12 12\n",
      "36 14 14\n",
      "37 13 13\n",
      "38 11 11\n",
      "39 17 17\n",
      "40 10 10\n",
      "41 15 15\n",
      "42 12 12\n",
      "43 13 13\n",
      "44 10 10\n",
      "45 13 13\n",
      "46 19 19\n",
      "47 9 9\n",
      "48 15 15\n",
      "49 15 15\n",
      "50 22 22\n",
      "51 23 23\n",
      "52 11 11\n",
      "53 12 12\n",
      "54 11 11\n",
      "55 20 20\n",
      "56 16 16\n",
      "57 14 14\n",
      "58 9 9\n",
      "59 9 9\n",
      "60 17 17\n",
      "61 12 12\n",
      "62 20 20\n",
      "63 25 25\n",
      "64 9 9\n",
      "65 12 12\n",
      "66 11 11\n",
      "67 15 15\n",
      "68 8 8\n",
      "69 24 24\n",
      "70 11 11\n",
      "71 12 12\n",
      "72 8 8\n",
      "73 13 13\n",
      "74 27 27\n",
      "75 16 16\n",
      "76 11 11\n",
      "77 11 11\n",
      "78 8 8\n",
      "79 9 9\n",
      "80 14 14\n",
      "81 12 12\n",
      "82 15 15\n",
      "83 14 14\n",
      "84 11 11\n",
      "85 12 12\n",
      "86 19 19\n",
      "87 12 12\n",
      "88 14 14\n",
      "89 8 8\n",
      "90 15 15\n",
      "91 13 13\n",
      "92 23 23\n",
      "93 16 16\n",
      "94 15 15\n",
      "95 8 8\n",
      "96 8 8\n",
      "97 28 28\n",
      "98 12 12\n",
      "99 11 11\n",
      "100 8 8\n",
      "101 20 20\n",
      "102 16 16\n",
      "103 8 8\n",
      "104 18 18\n",
      "105 15 15\n",
      "106 19 19\n",
      "107 20 20\n",
      "108 21 21\n",
      "109 9 9\n",
      "110 13 13\n",
      "111 13 13\n",
      "112 25 25\n",
      "113 17 17\n",
      "114 12 12\n",
      "115 9 9\n",
      "116 13 13\n",
      "117 22 22\n",
      "118 9 9\n",
      "119 13 13\n",
      "120 9 9\n",
      "121 20 20\n",
      "122 18 18\n",
      "123 14 14\n",
      "124 24 24\n",
      "125 10 10\n",
      "126 19 19\n",
      "127 15 15\n",
      "128 8 8\n",
      "129 14 14\n",
      "130 12 12\n",
      "131 12 12\n",
      "132 13 13\n",
      "133 21 21\n",
      "134 14 14\n",
      "135 13 13\n",
      "136 13 13\n",
      "137 13 13\n",
      "138 12 12\n",
      "139 13 13\n",
      "140 9 9\n",
      "141 24 24\n",
      "142 15 15\n",
      "143 16 16\n",
      "144 14 14\n",
      "145 23 23\n",
      "146 16 16\n",
      "147 27 27\n",
      "148 41 41\n",
      "149 11 11\n",
      "150 10 10\n",
      "151 12 12\n",
      "152 21 21\n",
      "153 14 14\n",
      "154 13 13\n",
      "155 13 13\n",
      "156 12 12\n",
      "157 14 14\n",
      "158 13 13\n",
      "159 17 17\n",
      "160 13 13\n",
      "161 9 9\n",
      "162 14 14\n",
      "163 13 13\n",
      "164 11 11\n",
      "165 13 13\n",
      "166 17 17\n",
      "167 15 15\n",
      "168 24 24\n",
      "169 12 12\n",
      "170 11 11\n",
      "171 29 29\n",
      "172 8 8\n",
      "173 15 15\n",
      "174 9 9\n",
      "175 14 14\n",
      "176 11 11\n",
      "177 14 14\n",
      "178 9 9\n",
      "179 25 25\n",
      "180 14 14\n",
      "181 16 16\n",
      "182 10 10\n",
      "183 18 18\n",
      "184 12 12\n",
      "185 9 9\n",
      "186 14 14\n",
      "187 15 15\n",
      "188 21 21\n",
      "189 16 16\n",
      "190 12 12\n",
      "191 35 35\n",
      "192 12 12\n",
      "193 9 9\n",
      "194 22 22\n",
      "195 14 14\n",
      "196 8 8\n",
      "197 12 12\n",
      "198 11 11\n",
      "199 15 15\n",
      "200 16 16\n",
      "201 9 9\n",
      "202 12 12\n",
      "203 9 9\n",
      "204 13 13\n",
      "205 17 17\n",
      "206 15 15\n",
      "207 19 19\n",
      "208 9 9\n",
      "209 10 10\n",
      "210 12 12\n",
      "211 18 18\n",
      "212 11 11\n",
      "213 9 9\n",
      "214 13 13\n",
      "215 18 18\n",
      "216 13 13\n",
      "217 9 9\n",
      "218 12 12\n",
      "219 14 14\n",
      "220 9 9\n",
      "221 14 14\n",
      "222 19 19\n",
      "223 20 20\n",
      "224 10 10\n",
      "225 15 15\n",
      "226 16 16\n",
      "227 13 13\n",
      "228 13 13\n",
      "229 13 13\n",
      "230 11 11\n",
      "231 13 13\n",
      "232 13 13\n",
      "233 12 12\n",
      "234 19 19\n",
      "235 9 9\n",
      "236 10 10\n",
      "237 24 24\n",
      "238 23 23\n",
      "239 13 13\n",
      "240 18 18\n",
      "241 15 15\n",
      "242 11 11\n",
      "243 13 13\n",
      "244 11 11\n",
      "245 9 9\n",
      "246 8 8\n",
      "247 9 9\n",
      "248 12 12\n",
      "249 24 24\n",
      "250 27 27\n",
      "251 8 8\n",
      "252 15 15\n",
      "253 17 17\n",
      "254 15 15\n",
      "255 16 16\n",
      "256 12 12\n",
      "257 13 13\n",
      "258 12 12\n",
      "259 15 15\n",
      "260 16 16\n",
      "261 12 12\n",
      "262 15 15\n",
      "263 12 12\n",
      "264 18 18\n",
      "265 9 9\n",
      "266 26 26\n",
      "267 25 25\n",
      "268 9 9\n",
      "269 11 11\n",
      "270 17 17\n",
      "271 12 12\n",
      "272 10 10\n",
      "273 12 12\n",
      "274 33 33\n",
      "275 12 12\n",
      "276 28 28\n",
      "277 18 18\n",
      "278 19 19\n",
      "279 21 21\n",
      "280 19 19\n",
      "281 12 12\n",
      "282 18 18\n",
      "283 25 25\n",
      "284 15 15\n",
      "285 9 9\n",
      "286 9 9\n",
      "287 30 30\n",
      "288 12 12\n",
      "289 11 11\n",
      "290 20 20\n",
      "291 16 16\n",
      "292 9 9\n",
      "293 18 18\n",
      "294 9 9\n",
      "295 13 13\n",
      "296 13 13\n",
      "297 8 8\n",
      "298 10 10\n",
      "299 8 8\n",
      "300 13 13\n",
      "301 17 17\n",
      "302 8 8\n",
      "303 9 9\n",
      "304 18 18\n",
      "305 13 13\n",
      "306 16 16\n",
      "307 16 16\n",
      "308 14 14\n",
      "309 13 13\n",
      "310 13 13\n",
      "311 9 9\n",
      "312 18 18\n",
      "313 21 21\n",
      "314 12 12\n",
      "315 12 12\n",
      "316 8 8\n",
      "317 9 9\n",
      "318 13 13\n",
      "319 11 11\n",
      "320 8 8\n",
      "321 11 11\n",
      "322 16 16\n",
      "323 12 12\n",
      "324 12 12\n",
      "325 16 16\n",
      "326 22 22\n",
      "327 11 11\n",
      "328 14 14\n",
      "329 9 9\n",
      "330 13 13\n",
      "331 13 13\n",
      "332 19 19\n",
      "333 12 12\n",
      "334 13 13\n",
      "335 9 9\n",
      "336 16 16\n",
      "337 9 9\n",
      "338 11 11\n",
      "339 9 9\n",
      "340 16 16\n",
      "341 27 27\n",
      "342 15 15\n",
      "343 28 28\n",
      "344 18 18\n",
      "345 19 19\n",
      "346 20 20\n",
      "347 9 9\n",
      "348 11 11\n",
      "349 15 15\n",
      "350 8 8\n",
      "351 8 8\n",
      "352 12 12\n",
      "353 10 10\n",
      "354 12 12\n",
      "355 12 12\n",
      "356 14 14\n",
      "357 14 14\n",
      "358 8 8\n",
      "359 8 8\n",
      "360 24 24\n",
      "361 15 15\n",
      "362 15 15\n",
      "363 8 8\n",
      "364 10 10\n",
      "365 30 30\n",
      "366 14 14\n",
      "367 17 17\n",
      "368 19 19\n",
      "369 13 13\n",
      "370 11 11\n",
      "371 16 16\n",
      "372 29 29\n",
      "373 10 10\n",
      "374 8 8\n",
      "375 13 13\n",
      "376 8 8\n",
      "377 12 12\n",
      "378 17 17\n",
      "379 9 9\n",
      "380 11 11\n",
      "381 14 14\n",
      "382 12 12\n",
      "383 19 19\n",
      "384 16 16\n",
      "385 8 8\n",
      "386 19 19\n",
      "387 14 14\n",
      "388 14 14\n",
      "389 17 17\n",
      "390 18 18\n",
      "391 19 19\n",
      "392 11 11\n",
      "393 9 9\n",
      "394 16 16\n",
      "395 12 12\n",
      "396 16 16\n",
      "397 13 13\n",
      "398 21 21\n",
      "399 10 10\n",
      "400 13 13\n",
      "401 16 16\n",
      "402 25 25\n",
      "403 12 12\n",
      "404 13 13\n",
      "405 16 16\n",
      "406 13 13\n",
      "407 13 13\n",
      "408 17 17\n",
      "409 12 12\n",
      "410 13 13\n",
      "411 11 11\n",
      "412 9 9\n",
      "413 8 8\n",
      "414 13 13\n",
      "415 14 14\n",
      "416 11 11\n",
      "417 11 11\n",
      "418 13 13\n",
      "419 15 15\n",
      "420 8 8\n",
      "421 18 18\n",
      "422 16 16\n",
      "423 14 14\n",
      "424 12 12\n",
      "425 18 18\n",
      "426 9 9\n",
      "427 17 17\n",
      "428 13 13\n",
      "429 16 16\n",
      "430 20 20\n",
      "431 9 9\n",
      "432 18 18\n",
      "433 13 13\n",
      "434 9 9\n",
      "435 11 11\n",
      "436 20 20\n",
      "437 16 16\n",
      "438 17 17\n",
      "439 13 13\n",
      "440 9 9\n",
      "441 24 24\n",
      "442 22 22\n",
      "443 13 13\n",
      "444 14 14\n",
      "445 17 17\n",
      "446 18 18\n",
      "447 18 18\n",
      "448 8 8\n",
      "449 8 8\n",
      "450 17 17\n",
      "451 14 14\n",
      "452 9 9\n",
      "453 13 13\n",
      "454 10 10\n",
      "455 26 26\n",
      "456 13 13\n",
      "457 18 18\n",
      "458 11 11\n",
      "459 11 11\n",
      "460 8 8\n",
      "461 12 12\n",
      "462 9 9\n",
      "463 13 13\n",
      "464 9 9\n",
      "465 14 14\n",
      "466 12 12\n",
      "467 14 14\n",
      "468 18 18\n",
      "469 11 11\n",
      "470 18 18\n",
      "471 14 14\n",
      "472 14 14\n",
      "473 11 11\n",
      "474 11 11\n",
      "475 17 17\n",
      "476 13 13\n",
      "477 20 20\n",
      "478 9 9\n",
      "479 15 15\n",
      "480 20 20\n",
      "481 10 10\n",
      "482 11 11\n",
      "483 11 11\n",
      "484 12 12\n",
      "485 13 13\n",
      "486 8 8\n",
      "487 18 18\n",
      "488 14 14\n",
      "489 11 11\n",
      "490 18 18\n",
      "491 19 19\n",
      "492 9 9\n",
      "493 13 13\n",
      "494 14 14\n",
      "495 12 12\n",
      "496 8 8\n",
      "497 23 23\n",
      "498 10 10\n",
      "499 25 25\n",
      "500 12 12\n",
      "501 15 15\n",
      "502 12 12\n",
      "503 26 26\n",
      "504 13 13\n",
      "505 20 20\n",
      "506 12 12\n",
      "507 14 14\n",
      "508 9 9\n",
      "509 23 23\n",
      "510 28 28\n",
      "511 8 8\n",
      "512 11 11\n",
      "513 27 27\n",
      "514 17 17\n",
      "515 12 12\n",
      "516 17 17\n",
      "517 17 17\n",
      "518 12 12\n",
      "519 23 23\n",
      "520 13 13\n",
      "521 13 13\n",
      "522 9 9\n",
      "523 8 8\n",
      "524 17 17\n",
      "525 15 15\n"
     ]
    }
   ],
   "source": [
    "for_confusion_matrix = {}\n",
    "\n",
    "global_true =[]\n",
    "global_pred = []\n",
    "counting_normal = 0\n",
    "for caseid in list(resultdict.keys()):\n",
    "\n",
    "    for_confusion_matrix[int(caseid)] =[]\n",
    "    \n",
    "    prediction_list = []\n",
    "    \n",
    "    df = original_df[original_df['Case ID'] == int(caseid)].reset_index(drop=True)\n",
    "    for pos, t in enumerate(resultdict['%s'%(caseid)]):\n",
    "        prediction_label = 'Normal'\n",
    "\n",
    "        predictions = list(t.predicted.values())[0][0]\n",
    "        predictions_proba = predictions[0][0]\n",
    "        predictions_value = list(predictions[1])\n",
    "\n",
    "        if predictions  == 'Not Available':\n",
    "            prediction_label = 'Not Available'\n",
    "        else:\n",
    "            if t.true_label in predictions_value:\n",
    "                labelidx = predictions_value.index(t.true_label)\n",
    "\n",
    "                if predictions_proba[labelidx] <0.15:\n",
    "                    prediction_label = 'Anomalous'\n",
    "            else:\n",
    "                prediction_label = 'Anomalous'\n",
    "\n",
    "        if t.true_label != 'End':\n",
    "            prediction_list.append(prediction_label)\n",
    "\n",
    "                    \n",
    "    true_label_list = []\n",
    "\n",
    "    labellist = list(df['noise'])\n",
    "    actlist = list(df['Activity'])\n",
    "    for pos, t in enumerate(labellist):\n",
    "        if t == 'Start' or t == 'End':\n",
    "            continue\n",
    "        elif t == 'true':\n",
    "            true_label = 'Anomalous'\n",
    "        else:\n",
    "            true_label = 'Normal'\n",
    "        true_label_list.append(true_label)\n",
    "\n",
    "    \n",
    "    for pos, p in enumerate(prediction_list):\n",
    "        if p =='Not Available':\n",
    "            counting_normal +=1\n",
    "            continue\n",
    "        else:\n",
    "            global_pred.append(p)\n",
    "            global_true.append(true_label_list[pos])\n",
    "\n",
    "    print(caseid, len(true_label_list), len(prediction_list))\n",
    "#     for t in true_label_list:\n",
    "#         global_true.append(t)\n",
    "#     print(prediction_list)\n",
    "#     print(true_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6fd48318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7376 7376\n",
      "186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Anomalous       0.27      0.94      0.42      1036\n",
      "      Normal       0.98      0.59      0.74      6340\n",
      "\n",
      "    accuracy                           0.64      7376\n",
      "   macro avg       0.63      0.77      0.58      7376\n",
      "weighted avg       0.88      0.64      0.70      7376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for pos, t in enumerate(prediction_list):\n",
    "#     if t == 'Not Available':\n",
    "#         true_label_list.pop(pos)\n",
    "\n",
    "matrix = classification_report(y_true = global_true, y_pred = global_pred)\n",
    "print(len(global_true), len(global_pred))\n",
    "\n",
    "print(counting_normal)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "159cbbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Normal', 'Normal', 'Anomalous', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Anomalous', 'Anomalous', 'Normal']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "prediction_list = []\n",
    "for pos, t in enumerate(resultdict['484']):\n",
    "    prediction_correct= 'Normal'\n",
    "\n",
    "    predictions = list(t.predicted.values())[0][0]\n",
    "    predictions_proba = predictions[0][0]\n",
    "    predictions_label = list(predictions[1])\n",
    "\n",
    "    if t.true_label in predictions_label:\n",
    "        labelidx = predictions_label.index(t.true_label)\n",
    "        \n",
    "        if predictions_proba[labelidx] <0.01:\n",
    "            prediction_correct = 'Anomalous'\n",
    "    else:\n",
    "        prediction_correct = 'Anomalous'\n",
    "\n",
    "    prediction_list.append(prediction_correct)\n",
    "print(prediction_list)\n",
    "print(len(prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ab7dac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check credit history Anomalous Normal 2\n",
      "Check  application  form completeness Normal Anomalous 5\n",
      "Cancel application Anomalous Normal 10\n",
      "end_event_Loan  application canceled Anomalous Normal 11\n",
      "9 4 13\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "incorrect = 0\n",
    "total =0\n",
    "for pos, t in enumerate(prediction_list):\n",
    "    \n",
    "    if list(df['noise'])[pos+1] == 'true':\n",
    "        true_label = 'Anomalous'\n",
    "        \n",
    "    elif list(df['noise'])[pos+1] == 'End' :\n",
    "        true_label = 'Normal'\n",
    "       \n",
    "    else:\n",
    "        true_label = 'Normal'\n",
    "        \n",
    "    if t == true_label:\n",
    "        correct +=1\n",
    "    else:\n",
    "        print(list(df['Activity'])[pos+1], t, true_label, pos)\n",
    "        incorrect +=1\n",
    "    total +=1\n",
    "print(correct, incorrect, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f3fac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultdict2 ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06a5681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in resultdict.keys():\n",
    "    resultdict2[t] ={}\n",
    "    for x in resultdict[t]:\n",
    "        resultdict2[t]['Event_%s'%(x.prefix_length)] =[x.predicted, x.true_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b8ec8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('result_rf.pkl', 'wb') as fp:\n",
    "    pickle.dump(resultdict2, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
