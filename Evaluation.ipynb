{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a1dd403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "import numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support  as score\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df0268de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/loan_baseline.pnml_noise_0.15_iteration_1_seed_614_simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15741703",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result_rf.pkl', 'rb') as fp:\n",
    "    data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "894c988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalous_or_not(result, caseid):\n",
    "    '''\n",
    "    Determine following activity is anomalous or not\n",
    "    If following activity is in the prediction candidates, it is normal. Otherwise, potential anomalous\n",
    "    ----------\n",
    "    Parameters\n",
    "    result: dict\n",
    "        Next activity prediction result\n",
    "    caseid: str\n",
    "    ----------\n",
    "    Return\n",
    "    anomalous_list: list\n",
    "        List with each event is anomaloy or not\n",
    "    '''\n",
    "    anomalous_list=[]\n",
    "    for x in result[caseid]:\n",
    "        event = result[caseid][x]\n",
    "        true_label = event[1]\n",
    "        predictions = event[0]\n",
    "        event_anomalous = 'Not Available'\n",
    "        for y in list(predictions.values()):\n",
    "            candidate_list = y[0]\n",
    "            detection_result = 'Not Available'\n",
    "\n",
    "            if candidate_list != 'Not Available':\n",
    "                candidates = y[0][1]\n",
    "                detection_result = 'Not Available'\n",
    "                if true_label in candidates:\n",
    "                    detection_result = 'Normal'\n",
    "                else:\n",
    "                    detection_result = 'Potential anomalous'\n",
    "        event_anomalous = detection_result\n",
    "        anomalous_list.append(event_anomalous)\n",
    "    \n",
    "    return anomalous_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b144791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomalous_or_not_detail(result, caseid):\n",
    "    '''\n",
    "    Determine following activity is anomalous or not\n",
    "    If following activity is in the prediction candidates, it is normal. Otherwise, potential anomalous\n",
    "    ----------\n",
    "    Parameters\n",
    "    result: dict\n",
    "        Next activity prediction result\n",
    "    caseid: str\n",
    "    ----------\n",
    "    Return\n",
    "    anomalous_list: list\n",
    "        List with each event is anomaloy or not\n",
    "    '''\n",
    "    anomalous_list=[]\n",
    "    for x in result[caseid]:\n",
    "        anomalous_detail = []\n",
    "        event = result[caseid][x]\n",
    "        true_label = event[1]\n",
    "        predictions = event[0]\n",
    "        event_anomalous = 'Not Available'\n",
    "        for y in list(predictions.values()):\n",
    "            candidate_list = y[0]\n",
    "            detection_result = 'Not Available'\n",
    "\n",
    "            if candidate_list != 'Not Available':\n",
    "                candidates = y[0][1]\n",
    "                detection_result = 'Not Available'\n",
    "                if true_label in candidates:\n",
    "                    detection_result = 'Normal'\n",
    "                else:\n",
    "                    detection_result = 'Potential anomalous'\n",
    "            anomalous_detail.append((detection_result, y[1]))\n",
    "        anomalous_list.append(anomalous_detail)\n",
    "    \n",
    "    return anomalous_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "406764f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "caseidlist = list(data.keys())\n",
    "anomalous_result ={}\n",
    "for caseid in caseidlist:\n",
    "    anomalous_result[caseid]= anomalous_or_not_detail(data, caseid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bf60bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       Case ID                                Activity       Complete Timestamp      Variant  Variant index lifecycle:transition  noise\n",
      "0           0                                   Start  2017-09-15 14:46:25.000   Variant 17             17                Start  Start\n",
      "1           0  start_event_Loan  application received  2017-09-15 14:46:25.000   Variant 17             17             complete    NaN\n",
      "2           0   Check  application  form completeness  2017-09-15 15:14:23.349   Variant 17             17             complete    NaN\n",
      "3           0                    Send acceptance pack  2017-09-15 15:14:23.349   Variant 17             17                  NaN   true\n",
      "4           0                       Appraise property  2017-09-15 17:15:52.828   Variant 17             17             complete    NaN\n",
      "...       ...                                     ...                      ...          ...            ...                  ...    ...\n",
      "8609      525                        Assess loan risk  2018-12-31 18:15:08.422  Variant 472            472             complete    NaN\n",
      "8610      525                      Assess eligibility  2018-12-31 19:29:43.172  Variant 472            472             complete    NaN\n",
      "8611      525                      Reject application  2018-12-31 22:31:29.104  Variant 472            472             complete    NaN\n",
      "8612      525     end_event_Loan application rejected  2018-12-31 23:49:41.599  Variant 472            472             complete    NaN\n",
      "8613      525                                     End  2018-12-31 23:49:41.599  Variant 472            472                  End    End\n",
      "\n",
      "[8614 rows x 7 columns]>\n",
      "0       Start\n",
      "1         NaN\n",
      "2         NaN\n",
      "3        true\n",
      "4         NaN\n",
      "        ...  \n",
      "8609      NaN\n",
      "8610      NaN\n",
      "8611      NaN\n",
      "8612      NaN\n",
      "8613      End\n",
      "Name: noise, Length: 8614, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.head)\n",
    "print(df['noise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86016a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8088\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "\n",
    "for pos, x in enumerate(list(df['noise'])):\n",
    "    if list(df['Activity'])[pos] != 'End':\n",
    "        if x == 'Start':\n",
    "            x = np.nan\n",
    "\n",
    "        true_labels.append(x)\n",
    "print(len(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59f1f49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8088\n"
     ]
    }
   ],
   "source": [
    "case_event_result_dict = {}\n",
    "predicted_labels = []\n",
    "for x in anomalous_result:\n",
    "    case_event_result_dict[x] = []\n",
    "    for pos, t in enumerate(anomalous_result[x]):\n",
    "        case_event_result_dict[x].append([pos+1, t[0][0]])\n",
    "        predicted_labels.append(t[0][0])\n",
    "print(len(predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87715d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5448 7841\n",
      "0.6948093355439358\n"
     ]
    }
   ],
   "source": [
    "total_predictions  =0\n",
    "correct_prediction =0\n",
    "true_label =0\n",
    "\n",
    "true_label2=[]\n",
    "predict_label2=[]\n",
    "for pos,t in enumerate(predicted_labels):\n",
    "    if predicted_labels[pos] != 'Not Available':\n",
    "        if true_labels[pos] == 'true':\n",
    "            true_label = 'Potential anomalous'\n",
    "        elif np.isnan(true_labels[pos]):\n",
    "            true_label = 'Normal'\n",
    "        \n",
    "        true_label2.append(true_label)\n",
    "        predict_label2.append(predicted_labels[pos])\n",
    "        if true_label == predicted_labels[pos]:\n",
    "            correct_prediction +=1\n",
    "        total_predictions +=1\n",
    "print(correct_prediction, total_predictions)\n",
    "print(correct_prediction/total_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b109c646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "             Normal       0.86      0.77      0.81      6810\n",
      "Potential anomalous       0.12      0.21      0.15      1031\n",
      "\n",
      "           accuracy                           0.69      7841\n",
      "          macro avg       0.49      0.49      0.48      7841\n",
      "       weighted avg       0.77      0.69      0.73      7841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_label2, predict_label2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "661b8cbc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0.01\n",
      "Noise           \n",
      "0.1500  0.862810\n",
      "0.1250  0.887906\n",
      "0.0900  0.899434\n",
      "0.0750  0.937233\n",
      "0.0490  0.953782\n",
      "0.0249  0.982110\n",
      "\n",
      "\n",
      "            0.01\n",
      "Noise           \n",
      "0.1500  0.787777\n",
      "0.1250  0.815028\n",
      "0.0900  0.786051\n",
      "0.0750  0.809334\n",
      "0.0490  0.781988\n",
      "0.0249  0.800630\n",
      "\n",
      "\n",
      "            0.01\n",
      "Noise           \n",
      "0.1500  0.823588\n",
      "0.1250  0.849907\n",
      "0.0900  0.838929\n",
      "0.0750  0.868600\n",
      "0.0490  0.859383\n",
      "0.0249  0.882133\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "threshold = [0.01]\n",
    "window_size = 50\n",
    "retraining_size = 15\n",
    "\n",
    "dataset = ['loan_baseline.pnml_noise_0.15_iteration_1_seed_614_sample.pkl',\n",
    "'loan_baseline.pnml_noise_0.125_iteration_1_seed_27126_sample.pkl',\n",
    "'loan_baseline.pnml_noise_0.09999999999999999_iteration_1_seed_14329_sample.pkl',\n",
    "'loan_baseline.pnml_noise_0.075_iteration_1_seed_73753_sample.pkl',\n",
    "'loan_baseline.pnml_noise_0.049999999999999996_iteration_1_seed_42477_sample.pkl',\n",
    "'loan_baseline.pnml_noise_0.024999999999999998_iteration_1_seed_68964_sample.pkl']\n",
    "\n",
    "\n",
    "noiselist = [0.15,0.125,0.09,0.075,0.049,0.0249]\n",
    "\n",
    "precisiondf = pd.DataFrame(columns=['Noise'])\n",
    "precisiondf['Noise'] = noiselist\n",
    "precisiondf = precisiondf.set_index(precisiondf['Noise'])\n",
    "\n",
    "recalldf = pd.DataFrame(columns=['Noise'])\n",
    "recalldf['Noise'] = noiselist\n",
    "recalldf = recalldf.set_index(recalldf['Noise'])\n",
    "\n",
    "fscoredf = pd.DataFrame(columns=['Noise'])\n",
    "fscoredf['Noise'] = noiselist\n",
    "fscoredf = fscoredf.set_index(fscoredf['Noise'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for pos1, data in enumerate(dataset):\n",
    "\n",
    "    for thr in threshold:\n",
    "#         rf_name = './result/rf_thr%s_%s'%(thr, data)\n",
    "#         iso_name = './result/iso_cont%s_%s'%(thr, data)\n",
    "        sp_name = './result/rf/rf_thr%s_window%s_retraining_%s_%s'%(thr, window_size, retraining_size, data)\n",
    "        unsp_name = './result/ocsvm/ocsvm_cont%s_window%s_retraining_%s_%s'%(thr, window_size, retraining_size, data)\n",
    "\n",
    "\n",
    "        with open(sp_name, 'rb') as f:\n",
    "            sp_data = pickle.load(f)\n",
    "\n",
    "        with open(unsp_name, 'rb') as f:\n",
    "            unsp_data = pickle.load(f)\n",
    "\n",
    "        sp_y_pred_avail= []\n",
    "        sp_y_true_avail = []\n",
    "        unsp_y_pred_avail = []\n",
    "        unsp_y_true_avail = []\n",
    "\n",
    "        for pos, t in enumerate(sp_data['y_pred']):\n",
    "            if t != 'Not Available' and unsp_data['y_pred'][pos] != 'Not Available':\n",
    "                sp_y_pred_avail.append(t)\n",
    "                sp_y_true_avail.append(sp_data['y_true'][pos])\n",
    "\n",
    "                unsp_y_pred_avail.append(unsp_data['y_pred'][pos])\n",
    "                unsp_y_true_avail.append(unsp_data['y_true'][pos])\n",
    "\n",
    "#         precision, recall, fscore, support = score(y_true = sp_y_true_avail, y_pred = sp_y_pred_avail)\n",
    "        precision, recall, fscore, support = score(y_true = unsp_y_true_avail, y_pred = unsp_y_pred_avail)\n",
    "        precisiondf.loc[noiselist[pos1],thr] = precision[1]\n",
    "        recalldf.loc[noiselist[pos1],thr] = recall[1]\n",
    "        fscoredf.loc[noiselist[pos1],thr] = fscore[1]\n",
    "        \n",
    "precisiondf = precisiondf.drop(columns=['Noise'])\n",
    "recalldf = recalldf.drop(columns=['Noise'])\n",
    "fscoredf = fscoredf.drop(columns=['Noise'])\n",
    "print(precisiondf)\n",
    "print('\\n')\n",
    "print(recalldf)\n",
    "print('\\n')\n",
    "print(fscoredf)\n",
    "    #     print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1083c9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0.01      0.01      0.01\n",
      "Noise                               \n",
      "0.1500  0.978628  0.140006  0.244967\n",
      "0.1250  0.986711  0.152647  0.264392\n",
      "0.0900  0.985392  0.176667  0.299616\n",
      "0.0750  0.990930  0.194165  0.324706\n",
      "0.0490  0.991339  0.245666  0.393755\n",
      "0.0249  0.995477  0.366345  0.535588\n",
      "            0.01\n",
      "Noise           \n",
      "0.1500  0.978628\n",
      "0.1250  0.986711\n",
      "0.0900  0.985392\n",
      "0.0750  0.990930\n",
      "0.0490  0.991339\n",
      "0.0249  0.995477\n",
      "\n",
      "\n",
      "            0.01\n",
      "Noise           \n",
      "0.1500  0.140006\n",
      "0.1250  0.152647\n",
      "0.0900  0.176667\n",
      "0.0750  0.194165\n",
      "0.0490  0.245666\n",
      "0.0249  0.366345\n",
      "\n",
      "\n",
      "            0.01\n",
      "Noise           \n",
      "0.1500  0.244967\n",
      "0.1250  0.264392\n",
      "0.0900  0.299616\n",
      "0.0750  0.324706\n",
      "0.0490  0.393755\n",
      "0.0249  0.535588\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "threshold = [0.01]\n",
    "window_size = 100\n",
    "retraining_size = 20\n",
    "\n",
    "dataset = ['loan_baseline.pnml_noise_0.15_iteration_1_seed_614_sample.pkl',\n",
    "'loan_baseline.pnml_noise_0.125_iteration_1_seed_27126_sample.pkl',\n",
    "'loan_baseline.pnml_noise_0.09999999999999999_iteration_1_seed_14329_sample.pkl',\n",
    "'loan_baseline.pnml_noise_0.075_iteration_1_seed_73753_sample.pkl',\n",
    "'loan_baseline.pnml_noise_0.049999999999999996_iteration_1_seed_42477_sample.pkl',\n",
    "'loan_baseline.pnml_noise_0.024999999999999998_iteration_1_seed_68964_sample.pkl']\n",
    "\n",
    "\n",
    "noiselist = [0.15,0.125,0.09,0.075,0.049,0.0249]\n",
    "\n",
    "precisiondf = pd.DataFrame(columns=['Noise'])\n",
    "precisiondf['Noise'] = noiselist\n",
    "precisiondf = precisiondf.set_index(precisiondf['Noise'])\n",
    "\n",
    "recalldf = pd.DataFrame(columns=['Noise'])\n",
    "recalldf['Noise'] = noiselist\n",
    "recalldf = recalldf.set_index(recalldf['Noise'])\n",
    "\n",
    "fscoredf = pd.DataFrame(columns=['Noise'])\n",
    "fscoredf['Noise'] = noiselist\n",
    "fscoredf = fscoredf.set_index(fscoredf['Noise'])\n",
    "\n",
    "\n",
    "for pos1, data in enumerate(dataset):\n",
    "\n",
    "    for thr in threshold:\n",
    "#         rf_name = './result/rf_thr%s_%s'%(thr, data)\n",
    "#         iso_name = './result/iso_cont%s_%s'%(thr, data)\n",
    "        sp_name = './result/rf/rf_thr%s_window%s_retraining_%s_%s'%(thr, window_size, retraining_size, data)\n",
    "        unsp_name = './result/ae/ae_cont%s_window%s_retraining_%s_%s'%(thr, window_size, retraining_size, data)\n",
    "\n",
    "\n",
    "        with open(sp_name, 'rb') as f:\n",
    "            sp_data = pickle.load(f)\n",
    "\n",
    "        with open(unsp_name, 'rb') as f:\n",
    "            unsp_data = pickle.load(f)\n",
    "\n",
    "        sp_y_pred_avail= []\n",
    "        sp_y_true_avail = []\n",
    "        unsp_y_pred_avail = []\n",
    "        unsp_y_true_avail = []\n",
    "\n",
    "        for pos, t in enumerate(sp_data['y_pred']):\n",
    "            if t != 'Not Available' and unsp_data['y_pred'][pos] != 'Not Available':\n",
    "                sp_y_pred_avail.append(t)\n",
    "                sp_y_true_avail.append(sp_data['y_true'][pos])\n",
    "\n",
    "                unsp_y_pred_avail.append(unsp_data['y_pred'][pos])\n",
    "                unsp_y_true_avail.append(unsp_data['y_true'][pos])\n",
    "\n",
    "#         precision, recall, fscore, support = score(y_true = sp_y_true_avail, y_pred = sp_y_pred_avail)\n",
    "        precision, recall, fscore, support = score(y_true = unsp_y_true_avail, y_pred = unsp_y_pred_avail)\n",
    "        precisiondf.loc[noiselist[pos1],thr] = precision[1]\n",
    "        recalldf.loc[noiselist[pos1],thr] = recall[1]\n",
    "        fscoredf.loc[noiselist[pos1],thr] = fscore[1]\n",
    "        \n",
    "precisiondf = precisiondf.drop(columns=['Noise'])\n",
    "recalldf = recalldf.drop(columns=['Noise'])\n",
    "fscoredf = fscoredf.drop(columns=['Noise'])\n",
    "print(pd.concat([precisiondf,recalldf,fscoredf],axis=1))\n",
    "print(precisiondf)\n",
    "print('\\n')\n",
    "print(recalldf)\n",
    "print('\\n')\n",
    "print(fscoredf)\n",
    "    #     print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ba947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
